{"meta":{"title":"West to the Northwest","subtitle":"发上等愿 结中等缘 享下等福 择高处立 寻平处往 向宽处行","description":"try to look 5 years ahead","author":"zero","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-12-31T10:14:34.000Z","updated":"2018-12-31T10:16:12.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"Do. or do not. There is no try."},{"title":"categories","date":"2018-12-31T10:11:47.000Z","updated":"2018-12-31T10:12:15.000Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-31T10:13:00.000Z","updated":"2018-12-31T10:13:19.000Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"flink task之间的数据交换","slug":"flink-task之间的数据交换","date":"2019-10-04T07:10:02.000Z","updated":"2019-10-05T16:31:34.103Z","comments":true,"path":"2019/10/04/flink-task之间的数据交换/","link":"","permalink":"http://yoursite.com/2019/10/04/flink-task之间的数据交换/","excerpt":"","text":"由于比赛需要，这部分是非常重要的内容，所以自己手动翻译一下。 Flink中数据交换的构建遵循以下设计原则 数据交换的控制流是接收方发出的，这与mapreduce相似。 数据交换的数据流，也就是实际数据传输通过IntermediateResult这个提法来抽象，并且是可插拔的，这意味着系统能够用相同的实现同时支持批流数据传输数据交换包括几个对象，包括： JobManager 这是主节点，负责调度任务，恢复以及协调，通过ExecutionGraph数据结构保存job执行的全貌 TaskManagers 这是工作节点，一个TM在线程级别并发执行多个task。每个TM还包含了一个CommunicationManager（CM在task之间共享），以及一个MemoryManager（MM，也是在task之间共享）。TM之间可以通过建立好的TCP连接交换数据。 要注意的是在Flink里面，是TM而不是task来通过网络交换数据，也就是说同一个TM的数据交换是被它里面的多个task多路复用的。 ExecutionGraph： 执行图是包含着job计算的基础事实的数据结构，它由代表着计算task的执行节点（ExecutionVertex）组成。节点通过ExecutionEdges执行边（EE）连接到中间结果。 JM里面有一些逻辑数据结构，他们有他们的运行时等价结构来负责TM内部的世界数据处理。 对于IntermediateResultPartition的运行时等价结构叫做ResultPartition。ResultPartition（RP）代表一个BufferWriter写的数据块，比如，一个task产生的数据块。一个RP是Result Subpartitions（RSs）的集合。这是为了区分分发给不同的接收者产生的数据结构，比如说在一个reduce或者join操作中的一个partitioning shuffle 操作。 ResultSubpartition(RS) 代表了有一个operator创建的数据的分区，同时还包括了把这个数据分区转发给接受放operator的逻辑。特定RS的实现决定了实际的数据传输逻辑，这是一个可插拔的机制，运行系统支持多种数据传输，比如PipelinedSubpartition是一个流水线的实现，支持流数据交换而SpillableSubpartition是一个阻塞的实现来支持批数据交换。 InputGate: 在接收方的RP的等价类。它负责收集数据buffer，并且在上游处理他们。 InputChannel：在接收方的RS等价类。它负责收集特定数据分区的数据buffer。 Buffer: 参看 https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=53741525 Serializers and deserializers reliably convert typed records into raw byte buffers and vice versa, handling records that span multiple buffers, etc. 数据交换的控制流 这张图代表了一个简单的包括两个并发的task的map-reduce job的执行。我们有两个TM，每个TM里面有两个task（一个map task和一个reduce task），两个TM分别运行在两个不同的节点中，一个JobManager运行在第三个节点中。我们关注tasks M1和R2之间的数据传输的初始化。数据传输用粗箭头代表，消息用细箭头表示。首先，M1产生一个 ResultPartition (RP1) (arrow 1) 当这个RP可以被消耗的时候，它会通知JobManager（arrow 2）.JobManager会通知这个partition的潜在接收者（任务R1和R2）分区已经准备好了。如果接收者还没被调度执行，这会触发接收者task的部署（箭头3a和3b）。然后，接收者会从RP请求数据（箭头4a和4b）。这会初始化task之间的数据传输(5a 5b)，这个传输可能是本地传输(5a)或者通过TaskManager的网络栈传输（5b）。当RP决定通知JobManager它可以被使用了的时候，这个过程保证了设计上的自由度。举个例子，如果RP1在通知JM之前，就把所有记录完全写到一个文件，那么数据交换基本上和在hadoop里面实现的批数据交换相同，如果RPI每产生一个记录就通知JM，就触发了一个流数据交换。 两个task之间的一个byte buffer的传输","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"flink","slug":"flink","permalink":"http://yoursite.com/tags/flink/"},{"name":"stream processing","slug":"stream-processing","permalink":"http://yoursite.com/tags/stream-processing/"}]},{"title":"20190821","slug":"20190821","date":"2019-08-21T01:59:49.000Z","updated":"2019-08-21T01:59:49.466Z","comments":true,"path":"2019/08/21/20190821/","link":"","permalink":"http://yoursite.com/2019/08/21/20190821/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"锁的发展","slug":"锁的发展","date":"2019-03-21T01:54:18.000Z","updated":"2019-03-21T01:55:31.000Z","comments":true,"path":"2019/03/21/锁的发展/","link":"","permalink":"http://yoursite.com/2019/03/21/锁的发展/","excerpt":"","text":"锁的发展基本上就是5个阶段，第一个阶段粗粒度的锁开始，一个锁管一个对象，这样过度序列化。第二个阶段是通过细粒度的锁，乐观的锁，放松一致性的锁等等。但是这种锁的容易做错，或者造成优先级倒置，死锁等等问题。特别是大规模系统中，锁的使用都写在代码注释里面，做着做着就失传了，靠看代码维持。第三个阶段是CAS阶段，就是通过原子操作实现无锁数据结构，这种方法能够多线程协同完成工作，上限很高，但是代码可维护性不是很好，通常是难以接续传男不传女传南不传北传胖不传瘦。第四个阶段和第五个阶段都是事务化阶段，分别是软件事务化和硬件事务化。 和传统在静态，从逻辑上判断关键区域不同，TSX让处理器来动态决定是否线程需要串行执行关键区，这里的动态是相对我们考虑什么时候使用锁的时候的静态逻辑分析来说的，如果一次执行中，同步是不需要的，那么不需要任何的跨线程的序列化。如何判断是不是需要同步，intel通过分析用户定义的事务代码，建立事务中内存区域的读集合和写集合，动态监测发生在同一个cache行中的处理器间访问冲突，决定是否需要序列化事务的操作。","categories":[{"name":"总结","slug":"总结","permalink":"http://yoursite.com/categories/总结/"}],"tags":[{"name":"多处理器编程","slug":"多处理器编程","permalink":"http://yoursite.com/tags/多处理器编程/"}]},{"title":"在IntelliJ中使用flink的webUI","slug":"在IntelliJ中使用flink的webUI","date":"2019-03-08T05:47:17.000Z","updated":"2019-03-08T06:05:50.000Z","comments":true,"path":"2019/03/08/在IntelliJ中使用flink的webUI/","link":"","permalink":"http://yoursite.com/2019/03/08/在IntelliJ中使用flink的webUI/","excerpt":"","text":"为每个task或者operator收集的metric可以在dashboard可视化，在job的主页上，选择metrics标签页，在选择top graph中的一个task之后，你可以通过使用add metric下拉菜单选择要显示的metric 如何看到metrics–>修改工程的pom.xml文件I was able to start the Flink webui from IntelliJ by adding flink-runtime-web to the dependencies for my project. I did this by adding this to my pom.xml file:12345`\\&lt;dependency\\&gt; \\&lt;groupId\\&gt;org.apache.flink\\&lt;/groupId\\&gt; \\&lt;artifactId\\&gt;flink-runtime-web_2.11\\&lt;/artifactId\\&gt; \\&lt;version\\&gt;$&#123;flink.version&#125;\\&lt;/version\\&gt;\\&lt;/dependency\\&gt; `然后在类文件中加入下面代码123`Configuration config = new Configuration();config.setBoolean(ConfigConstants.LOCAL_START_WEBSERVER, true);StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(config); `","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"flink","slug":"flink","permalink":"http://yoursite.com/tags/flink/"},{"name":"stream processing","slug":"stream-processing","permalink":"http://yoursite.com/tags/stream-processing/"}]},{"title":"flink窗口","slug":"flink窗口","date":"2019-03-07T08:21:41.000Z","updated":"2019-03-08T06:05:46.000Z","comments":true,"path":"2019/03/07/flink窗口/","link":"","permalink":"http://yoursite.com/2019/03/07/flink窗口/","excerpt":"","text":"flink有丰富的窗口语义。 在这个训练中你会学到： 如何使用窗口来无限流上计算累计 flink支持什么类型的窗口 如何使用窗口累计来实现一个数据流程序Introduction想要在有界子集上计算累计分析对流处理时是很自然的，通常这些分析想要回答一下这些类的问题： 每分钟页面的访问 每个用户每星期的会话数目 每分钟每个传感器的最大温度 使用flink计算窗口化的分析依赖于两个主要的抽象：一是窗口分配者把时间分配给窗口（并且在必要时创建新窗口），二是窗口函数，这些函数会被应用到分配到窗口的事件上。 flink的窗口API还有一个概念叫做Triggers，触发器。触发器决定什么时候调用窗口函数，还有Evictors移除器，它负责从一个窗口中删除元素。 简单来说，你可以对一个键数据流这样应用窗口：1234`stream. .keyBy(\\&lt;key selector\\&gt;) .window(\\&lt;window assigner\\&gt;) .reduce|aggregate|process(\\&lt;window function\\&gt;) `You can also use windowing with non-keyed streams, but keep in mind that in this case, the processing will not be done in parallel:123`stream. .windowAll(\\&lt;window assigner\\&gt;) .reduce|aggregate|process(\\&lt;window function\\&gt;) ` 窗口函数对于如何处理窗口内容，你有三个基本选项： 像批一样，使用ProcessWindowFunction来迭代处理窗口内容； 增量处理，每向窗口分配一个事件就调用一个ReduceFunction或者AggregateFunction; 以上两者结合，当窗口触发时，由ReduceFunction或者AggregateFunction得到的预先累计的结果被提供给一个ProcessWindowFunction。 下面给出方法1和方法3的例子，每个例子中，我们都在一分钟ET窗口中寻找每个传感器的峰值，并且生成一个由（键，窗口结束时间戳，最大值）组成的元组。 ProcessWindowFunction Example123456789101112131415161718192021222324252627`DataStream\\&lt;SensorReading\\&gt; input = ...input .keyBy(“key”) .window(TumblingEventTimeWindows.of(Time.minutes(1))) .process(new MyWastefulMax());public static class MyWastefulMax extends ProcessWindowFunction\\&lt; SensorReading, // input type Tuple3\\&lt;String, Long, Integer\\&gt;, // output type Tuple, // key type TimeWindow\\&gt; &#123; // window type@Overridepublic void process( Tuple key, Context context, Iterable\\&lt;SensorReading\\&gt; events, Collector\\&lt;Tuple3\\&lt;String, Long, Integer\\&gt;\\&gt; out) &#123;int max = 0;for (SensorReading event : events) &#123; if (event.value \\&gt; max) max = event.value;&#125;// note the rather hideous castout.collect(new Tuple3\\&lt;\\&gt;((Tuple1\\&lt;String\\&gt;)key).f0, context.window().getEnd(), max));&#125;&#125; `在这个实现中要注意一些事情：键选择器做keyby的时候用“key”作为域名，这样编译器无法知道我们的键是strings，因此在ProcessWindowFunction里面要处理的键类型是元组。注意上面代码最后一行变态的转换。 所有分配到这个窗口的事件都需要缓冲在flink中直到窗口被触发，这是相对昂贵的操作。我们的ProcessWindowFunction函数接受了一个Context对象，从它可以得到窗口的信息，它的接口长这样：123456789`public abstract class Context implements java.io.Serializable &#123;public abstract W window();public abstract long currentProcessingTime();public abstract long currentWatermark();public abstract KeyedStateStore windowState();public abstract KeyedStateStore globalState();&#125; `windowState和globalState是你存储每个key，每个窗口或者全局每个Key信息的地方。举个例子，如果你要记录当前窗口的信息并且要在后续窗口处理中使用时，就需要他们。 Incremental Aggregation Example123456789101112131415161718192021222324252627`DataStream\\&lt;SensorReading\\&gt; input = ...input .keyBy(x -\\&gt; x.key) .window(TumblingEventTimeWindows.of(Time.minutes(1))) .reduce(new MyReducingMax(), new MyWindowFunction());private static class MyReducingMax implements ReduceFunction\\&lt;SensorReading\\&gt; &#123; public SensorReading reduce(SensorReading r1, SensorReading r2) &#123;return r1.value() \\&gt; r2.value() ? r1 : r2; &#125;&#125;private static class MyWindowFunction extends ProcessWindowFunction\\&lt; SensorReading, Tuple3\\&lt;String, Long, SensorReading\\&gt;, String, TimeWindow\\&gt; &#123; @Override public void process(String key,Context context,Iterable\\&lt;SensorReading\\&gt; maxReading,Collector\\&lt;Tuple2\\&lt;Long, SensorReading\\&gt;\\&gt; out) &#123;SensorReading max = maxReading.iterator().next();out.collect(new Tuple3\\&lt;String, Long, SensorReading\\&gt;(key, context.window().getStart(), max)); &#125;&#125; `在这个实现中，我们决定使用一个更鲁邦的键选择器， keyBy(x -> x.key) 同时注意Iterable\\&lt;SensorReading>这次只会包含一个读数，也就是预先累计的由MyReducingMax计算的最大值。 晚到事件默认情况下，当使用ET窗口时，晚到事件会被丢弃。有两个可选的窗口API函数给你对这个的控制。你可以把本来要丢弃的事件输出到一个另外的输出流中，使用旁路输出(https://github.com/zhuguoliang/FlinkTraining\\_CN/issues/5#issue-418167538)。这里有一个例子: 123456789`OutputTag\\&lt;Event\\&gt; lateTag = new OutputTag\\&lt;Event\\&gt;(&quot;late&quot;)&#123;&#125;;SingleOutputStreamOperator\\&lt;Event\\&gt; result = stream. .keyBy(...) .window(...) .process(...) .getSideOutput(lateTag); DataStream\\&lt;Event\\&gt; lateStream = result.getSideOutput(lateTag); `You can also specify an interval of allowed lateness during which the late events will continue to be assigned to the appropriate window(s) (whose state will have been retained). By default each late event will cause a late firing of the window function. By default the allowed lateness is 0. In other words, elements behind the watermark are dropped (or sent to the side output). For example:12345`stream. .keyBy(...) .window(...) .allowedLateness(Time.seconds(10)) .process(...); `SurprisesSome aspects of Flink’s windowing API may not behave in the way you would expect. Based on frequently asked questions on Stack Overflow(https://stackoverflow.com/questions/tagged/apache-flink) and the flink-user mailing list(https://flink.apache.org/community.html#mailing-lists), here are some facts about windows that may surprise you. Sliding Windows Make CopiesSliding window assigners can create lots of window objects, and will copy each event into every relevant window. For example, if you have sliding windows every 15 minutes that are 24-hours in length, each event will be copied into 4 * 24 = 96 windows. Time Windows are Aligned to the EpochJust because you are using hour-long processing-time windows and start your application running at 12:05 does not mean that the first window will close at 1:05. The first window will be 55 minutes long and close at 1:00. Windows Can Follow WindowsFor example, it works to do this:1234567`stream .keyBy(t -\\&gt; t.key) .timeWindow(\\&lt;time specification\\&gt;) .reduce(\\&lt;reduce function\\&gt;) .timeWindowAll(\\&lt;same time specification\\&gt;) .reduce(\\&lt;same reduce function\\&gt;) `You might expect Flink’s runtime to be smart enough to do this parallel pre-aggregation for you (provided you are using a ReduceFunction or AggregateFunction), but it’s not. No Results for Empty TimeWindowsWindows are only created when events are assigned to them. So if there are no events in a given time frame, no results will be reported. Late Events Can Cause Late MergesSession windows are based on an abstraction of windows that can merge. Each element is initially assigned to a new window, after which windows are merged whenever the gap between them is small enough. In this way, a late event can bridge the gap separating two previously separate sessions, producing a late merge. Evictors are Incompatible with Incremental AggregationThis is true simply by definition – you can’t evict elements you didn’t store. But this means that designs that depend on using Evictors are adopting something of an anti-pattern.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"flink","slug":"flink","permalink":"http://yoursite.com/tags/flink/"},{"name":"stream processing","slug":"stream-processing","permalink":"http://yoursite.com/tags/stream-processing/"}]},{"title":"flink源码阅读之一","slug":"flink源码阅读之一","date":"2019-02-13T14:13:08.000Z","updated":"2019-03-08T06:05:38.000Z","comments":true,"path":"2019/02/13/flink源码阅读之一/","link":"","permalink":"http://yoursite.com/2019/02/13/flink源码阅读之一/","excerpt":"","text":"","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"flink","slug":"flink","permalink":"http://yoursite.com/tags/flink/"},{"name":"stream processing","slug":"stream-processing","permalink":"http://yoursite.com/tags/stream-processing/"}]},{"title":"enable sysstat","slug":"enable-sysstat","date":"2019-01-19T13:10:11.000Z","updated":"2019-01-19T13:11:16.000Z","comments":true,"path":"2019/01/19/enable-sysstat/","link":"","permalink":"http://yoursite.com/2019/01/19/enable-sysstat/","excerpt":"","text":"systemctl restart sysstat.serviceOn Ubuntu 16.04 I just ran into this same issue. After some grousing around I found I needed to enable the service by editing the file /etc/default/sysstatChange ENABLED=”false” to true: Should sadc collect system activity informations? Valid valuesare “true” and “false”. Please do not put other values, theywill be overwritten by debconf!ENABLED=”true”Restart the service:systemctl restart sysstat.service","categories":[],"tags":[]},{"title":"计算存储分离之我见","slug":"计算存储分离之我见","date":"2018-12-31T12:30:10.000Z","updated":"2018-12-31T12:30:10.000Z","comments":true,"path":"2018/12/31/计算存储分离之我见/","link":"","permalink":"http://yoursite.com/2018/12/31/计算存储分离之我见/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"chandy lamport算法","slug":"chandy-lamport算法","date":"2018-12-31T12:29:55.000Z","updated":"2018-12-31T12:29:55.000Z","comments":true,"path":"2018/12/31/chandy-lamport算法/","link":"","permalink":"http://yoursite.com/2018/12/31/chandy-lamport算法/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"# Readings in Streaming Systems","slug":"Readings-in-Streaming-Systems","date":"2018-12-31T12:29:30.000Z","updated":"2018-12-31T12:30:28.000Z","comments":true,"path":"2018/12/31/Readings-in-Streaming-Systems/","link":"","permalink":"http://yoursite.com/2018/12/31/Readings-in-Streaming-Systems/","excerpt":"","text":"额","categories":[],"tags":[]},{"title":"Qcon18' blink","slug":"Qcon18-blink","date":"2018-12-31T12:17:05.000Z","updated":"2019-03-08T06:05:34.000Z","comments":true,"path":"2018/12/31/Qcon18-blink/","link":"","permalink":"http://yoursite.com/2018/12/31/Qcon18-blink/","excerpt":"","text":"流计算特点 低延迟（不一定非常低，不同于批处理） 快速容错（不同于批处理，要快） 通用的API （通用性决定用户数目） 易用性 （决定开发速度） 弹性 （可扩展性怎么样，能不能1w台机器） 高性能 早起流计算是批处理的，纯流计算是没有批的概念的，进行有状态的计算，所以需要一个能够固化保存的分布式存储，这通常是流计算系统的瓶颈。需要能够快速的完成检查点的恢复容错语义上：exactly once 》 at least once 至少一次开销小一些。最主流的是全局快照 chandy lamport算法。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"flink","slug":"flink","permalink":"http://yoursite.com/tags/flink/"},{"name":"stream processing","slug":"stream-processing","permalink":"http://yoursite.com/tags/stream-processing/"}]},{"title":"Qcon18' TIDB","slug":"Qcon18-TIDB","date":"2018-12-31T12:12:30.000Z","updated":"2018-12-31T12:15:37.000Z","comments":true,"path":"2018/12/31/Qcon18-TIDB/","link":"","permalink":"http://yoursite.com/2018/12/31/Qcon18-TIDB/","excerpt":"","text":"设计目标 水平扩展 高可用 ACID事务 SQL的数据库 发展历程 只在内存中 加入golevelDB做持久化 基于HBASE做分布式，但是发现下层软件栈厚，依赖过多 开发TIkv 选择用rust实现，选择没有GC的语言 选择rocksDB 用sysbench 性能没有达到预期，还有很多sql功能没有实现–》实现更好的sql层， tispark 测试很重要 单元测试 性能测试 chaos测试 混沌测试 突然杀死。。 测试的测试 工具很重要 自动化所有事情 混沌测试工具 调试工具 基础框架工具 jira/Confluence","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://yoursite.com/tags/分布式系统/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"Qcon18' smartx","slug":"Qcon18-smartx","date":"2018-12-31T12:05:58.000Z","updated":"2018-12-31T12:09:09.000Z","comments":true,"path":"2018/12/31/Qcon18-smartx/","link":"","permalink":"http://yoursite.com/2018/12/31/Qcon18-smartx/","excerpt":"","text":"如何构建元数据服务 failoverzookeeper 存储空间严格受限，所有数据在内存中。DHT无法精确控制，负载不均衡情况最终选择：levelDB+ ZOOKEEPER原因：轻量级，稳定 Log replication 数据认为成操作日志累加结果，记录操作日志即可拿到完整数据状态。 zookeeper选取meta server leader， zookeeper负责log持久化 其他的从zookeeper上拉取logfailover，当leader fail 重新选举，把没有消费完的日志重新消费，即可继续提供服务 数据存储引擎要求 可靠 性能 效率 容易debug LSM树问题 写放大 3倍 读放大300多倍 内核文件系统的问题： 内核文件系统，构建存储引擎没用到，文件系统为了单个磁盘设计对异步IO支持不好文件系统的日志操作带来写放大问题 用户空间的存储引擎，直接构建在块设备层之上目前的问题在于上下文切换。 未来：pmd实现在用户层，存储引擎实现在","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://yoursite.com/tags/分布式系统/"}]},{"title":"如何构建元数据服务","slug":"如何构建元数据服务","date":"2018-12-31T12:05:34.000Z","updated":"2018-12-31T12:05:34.000Z","comments":true,"path":"2018/12/31/如何构建元数据服务/","link":"","permalink":"http://yoursite.com/2018/12/31/如何构建元数据服务/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Linux 内核ELF中的特殊sections","slug":"Linux-内核ELF中的特殊sections","date":"2018-12-31T12:01:07.000Z","updated":"2018-12-31T12:03:22.000Z","comments":true,"path":"2018/12/31/Linux-内核ELF中的特殊sections/","link":"","permalink":"http://yoursite.com/2018/12/31/Linux-内核ELF中的特殊sections/","excerpt":"","text":"Linux内核有一些额外类型的section，被叫做特殊区，special sections这些区使用来实现很多内核特性 ELF有个头，有很多段，每个段又包括一个或者多个区域，每个段的长度和每个区的长度在ELF头里面指出。 链接器把相同类型的区和并成一个区，然后给它分配一个起始地址。 比较简单的和执行文件中的section和内核中的section,可以发现有很多特别的区。 这些区域的数目依赖于体系结构，x86_64有超过30个，ARM有10个特殊区域的定义在Linux链接器脚本中，这个默认的链接器脚本有区别，对应的文件存储在每个架构的子树中kernel/vmlinux.ld.S中这个文件使用一系列定义在linux/include/asm_generic/vmlinux.lds.h头文件中的宏中。 ARM平台连接脚本包含一个对特殊区域的简单易懂的定义. = ALIGN(4);start_ex_table = .;*(ex_table) stop___ex_table = .; 这个ex_table特殊区域四字节对其。链接器创建一堆标识符，也就是start_ex_table和stopex_table，然后这只他们的起始地址为ex_table的开始和结尾。 Linux函数可以用这些标识符来迭代ex_table的字节， 下面，根据Linux特殊区域中存储的信息对这些特殊区域进行分组， 在linux初始化时调用的函数放在.init.text区域，一旦系统个初始化之后，Linux用区域的delimiter来释放这个区域分配的页帧。 定义为__sched的函数被插入到.sched.text特殊区域，这样就会被get_wchan()函数忽略，这个函数在读取/proc/PID/wchan文件时调用，","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"内核","slug":"内核","permalink":"http://yoursite.com/tags/内核/"}]},{"title":"慢思考","slug":"慢思考","date":"2018-12-31T11:57:56.000Z","updated":"2018-12-31T11:58:25.000Z","comments":true,"path":"2018/12/31/慢思考/","link":"","permalink":"http://yoursite.com/2018/12/31/慢思考/","excerpt":"","text":"抽出固定的不受打扰的时间，来完成专注的工作和对话。 如果没有办法摆脱多任务并行，最好每天抽出一小时，不受打扰地完成一个任务 离线方法 首先找出一天中思考表现最好的时间段，（可以试着把安静的一小时安排在一天中不同的时间段，找出这个时间，但对于大多数人来说是清晨，或者可以在临睡之前的一小时） 在周日晚上抽出20分钟彻底离线，用于计划一周的工作，确定最重要的任务是哪些，安排在什么时间去做，确保每天都有充足的安静时间 每天抽出10分钟来安排第二天的事情，时间不应该晚于睡前1小时，在这10分钟里面，确定最重要的事情并且记下来，这样在睡觉的时候，存储脑就会提前开始工作。 如果需要阅读艰深的文本，最好打印出来，因为研究表明，在纸面上阅读更容易发现重要的细节或错误，而在屏幕上可能错过。 批量处理方法，减少任务切换次数 艾森豪威尔原理，重要的事情通常不紧急，紧急的事情通常不重要。 面对很多任务时，最好的处理方法就是直接查看日程安排个时间，如果没时间就拒绝。 你的优先级是什么，不光是工作，甚至包括整个人生 什么活动能为你带来最大的价值，最多的快乐。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"intel IOAT的用处","slug":"intel-IOAT的用处","date":"2018-12-31T11:55:11.000Z","updated":"2018-12-31T11:55:47.000Z","comments":true,"path":"2018/12/31/intel-IOAT的用处/","link":"","permalink":"http://yoursite.com/2018/12/31/intel-IOAT的用处/","excerpt":"","text":"DMA–>IOAT 之前对DMA的使用是从主机的内存直接传输到输入/输出设备，不需要主机CPU干预。一些网络例如Infiniband提供零拷贝数据传输。然而，这些解决方案都是用于在节点之间进行数据传输。之前的研究人员也尝试过使用DMA在节点内部进行大规模数据传输。很多这样的尝试失败的原因是由于DMA启动开销大，DRAM完成后的通知开销等开销问题。具体来说，要保证传输的内存页面不被swap出去，并且需要检查完成。 近期intel提出的IOAT引入了一个异步DMA拷贝引擎。 IOAT主要三个特性 分割头：IOAT优化TCPIP栈，控制器将网络数据分为头部数据和应用数据，存放在不同的buffer中，这样在进行网络报文数据处理的时候不会有应用数据污染cache。 使用DMA引擎进行异步拷贝：大部分接收报文处理时间用在将数据从内核buffer拷贝到用户buffer中的操作上。而且随着网络传输速度的加快，报文拷贝开销所占的时间比例越来越大。IOAT将拷贝操作放到一个额外的DMA引擎中处理。 多接收队列：大报文处理并不是CPU密集的，然而如果要处理很多小的报文会完全占用CPU，因此IOAT提供了多接收队列，这样请求可以由多个CPU同时处理。然而这个特性在LINUX平台上通常关闭？？ 主要的问题在于 由于内存控制器使用物理地址，因此内存操作会被打散为多个单独的页传输。 内存拷贝中可能出钱的源地址和目标地址的重合需要考虑。 拷贝引擎需要考虑数据传输之后的内存一致性。由内存控制器进行的数据传输需要考虑在处理器cache中存储的数据，因此在数据传输完成之后可能需要进行一个总线上的cache一致性事务。 下面这个链接是一个在线看代码的地方，下面是最新的对ioat支持https://elixir.free-electrons.com/linux/latest/source/drivers/dma/ioat/dma.c 在下面这个链接讨论了支持IOAT 的DCA相关的内核patch，基本实现在2007年。https://lwn.net/Articles/247493/","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"处理器设计","slug":"处理器设计","permalink":"http://yoursite.com/tags/处理器设计/"},{"name":"DMA","slug":"DMA","permalink":"http://yoursite.com/tags/DMA/"}]},{"title":"Go interface","slug":"Go-interface","date":"2018-12-31T11:48:37.000Z","updated":"2018-12-31T11:56:06.000Z","comments":true,"path":"2018/12/31/Go-interface/","link":"","permalink":"http://yoursite.com/2018/12/31/Go-interface/","excerpt":"","text":"go interfaceinterface是一种具有一组方法的类型，这些方法定义了interface的行为。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"2018的总结","slug":"2018的总结","date":"2018-12-31T10:20:31.000Z","updated":"2018-12-31T10:48:37.000Z","comments":true,"path":"2018/12/31/2018的总结/","link":"","permalink":"http://yoursite.com/2018/12/31/2018的总结/","excerpt":"","text":"窗外是雪后第二天的寒冷，坐在沙发上，我终于能总结这一年。如果说2017年是学生时代的终结，那么2018年，我真正的走向了职场，这一年参与了国产芯片的讨论，感受到了我们追赶intel的紧迫，同时，我也努力的在自主架构上实现了我之前特别感兴趣的cache划分机制，同时，又把intel的SPDK， DPDK搬到自主架构上来。讲真，在不是x86的带微码的机器上做一些东西还是很有意思的。随着事情的深入，我渐渐感到我的兴趣并不在架构相关上，封闭的架构在锁住别人的时候也锁住了自己，尽管资本已经在芯片领域里面狂欢了起来，可是我不在乎。我开始专注之前的兴趣方向，分布式系统。比较有意思的事情是，当我想和师兄合作的时候，又把我拉回了操作系统领域，我熟悉的做着自己早已经做了很多遍的调模块工作，尽管我想做的Rust数据库已经有了一些起色。聊完了技术，是时候回顾一下生活了，2018年，可能是我人生中最重要的一年，在介绍下认识了小添，这一年，我们相识，相恋，结婚了。我并不想和太多的人分享，因为这些事情对我太重要，我太想把它保护好。她是一个矛盾体，一个极端理想主义同时又极端现实主义的人，在医院的工作，见识了太多的人间冷暖，让她对人性没有太多的信心，而在内心里，她又渴望着完美的一切。而我，只希望能帮助她保护好对完美世界的期待，在生活的磕磕碰碰的烟火气息中，找到一些温暖的味道。这一年，读书上差强人意，只是零散阅读了几本东野圭吾的书，以及为了帮朋友弄数据，看了基本数据挖掘的书，再之外就是在《得到》里面听了一些名人的故事，一些名著的梗概，一些科幻的脉络。2018一切并不完美，我不急，每一步都在踏实地走着，2019，期待你的到来。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[]},{"title":"c++11和c++14区别","slug":"c-11和c-14区别","date":"2018-12-29T07:57:17.000Z","updated":"2018-12-31T11:40:04.000Z","comments":true,"path":"2018/12/29/c-11和c-14区别/","link":"","permalink":"http://yoursite.com/2018/12/29/c-11和c-14区别/","excerpt":"","text":"c++11 通过值决定对象类型 可以决定是否想要重载虚函数 可以使用Lambda表达式 新的用于遍历容器的for循环格式 auto_ptr 被 unique_ptr代替，更安全 线程库成为语言内部库，不需要包含外部库 在构建或者赋值的时候可以使用移动而不是复制。 这里使用移动而不是复制的方式很有意思，这是rust的重要特性 c++14 auto 也能作为返回值了 auto也能做lambda参数了 加入废弃一个类的快捷方式 可以使用二进制数","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"git提交规范","slug":"git提交规范","date":"2018-12-29T07:49:25.000Z","updated":"2018-12-31T05:38:25.000Z","comments":true,"path":"2018/12/29/git提交规范/","link":"","permalink":"http://yoursite.com/2018/12/29/git提交规范/","excerpt":"","text":"之前做Git提交写commit信息的时候，总是不够统一，以后分为七种 feat： 新功能 fix： 修补xxxBug docs：文档上的修改 style: 格式（不影响代码运行逻辑的变动） refactor：重构 test：测试上的修改 chore： 构建过程或者辅助工具的变动","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"Use the Device Mapper storage driver翻译","slug":"Use-the-Device-Mapper-storage-driver翻译","date":"2018-12-04T06:25:46.000Z","updated":"2018-12-31T05:38:25.000Z","comments":true,"path":"2018/12/04/Use-the-Device-Mapper-storage-driver翻译/","link":"","permalink":"http://yoursite.com/2018/12/04/Use-the-Device-Mapper-storage-driver翻译/","excerpt":"","text":"device mapper是一个基于内核的框架，用来在linux下支持很多高级的卷管理策略。docker的devicemapper存储驱动利用这个框架的thin provisioning以及快照功能来进行镜像和容器的管理。本文中docker的设备存储驱动标记为devicemapper, 内核中的框架为Device Mapper。 对于兼容的系统，devicemapper的支持已经包含在内核中，然而在docker中使用它需要进行一些配置。devicemapper驱动使用指定给docker的块设备来在块层操作，而不是在文件层，这些设备可以通过在docker host中增加物理存储来扩展，并且相比在操作系统层使用文件系统，这种方式表现更好。 预先要求 device mapper 存储驱动是在很多OS发型版中支持的DOCKER企业版上已经支持的存储驱动，详细请看产品兼容表。 device mapper也在docker社区版支持，支持操作系统包括 CentOS, Fedora, Ubuntu, 和 Debian. 修改存储驱动会使得你已经创建的所有容器在本地系统中无法访问。使用docker save来保存容器，并将现有容器推送到docker hub或者私有的仓库中，这样你就不需要因为修改驱动而重新创建了。 配置docker使用device mapper存储驱动注意在进行下面操作之前，必须满足预先要求。 配置loop-lvm模式测试","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"os","slug":"os","permalink":"http://yoursite.com/tags/os/"}]},{"title":"scrapy downloader中间件和spider中间件区别是什么？","slug":"scrapy-downloader中间件和spider中间件区别是什么？","date":"2018-09-07T08:56:00.000Z","updated":"2018-12-31T05:38:25.000Z","comments":true,"path":"2018/09/07/scrapy-downloader中间件和spider中间件区别是什么？/","link":"","permalink":"http://yoursite.com/2018/09/07/scrapy-downloader中间件和spider中间件区别是什么？/","excerpt":"","text":"使用scrapy自动创建的爬虫中middleware.py中自定义了两个中间件类，在我的理解中scrape的中间件没有什么区别，所以查了一下， 下载器中间件，尽管他们使用一样的接口，他们的目标不同dowlloader中间件修改请求和响应，或者生成请求来回答响应。他们并不直接与蜘蛛交互，这里面可以实现cookie， caching， proxy, 设置user-agent头等等。原理上是为downloader加入功能。 蜘蛛中间件修改传入和传出的东西，比如请求，item，exception以及start_requests. 它与下载器中间件共享基本功能，但是他们不能生成请求来回答响应。 他们位于蜘蛛和下载器之间，一个例子是过滤有坏的HTTP状态代码的回答。 While they have almost identical interfaces, they serve different purposes:• Downloader middlewares modify requests and responses or generate requests in response to responses. They don’t directly interact with spiders. Some examples are middlewares that implement cookies, caching, proxies, redirects, setting user-agent headers, etc. They just add functionality to the downloader system. • Spider middlewares modify things that pass in and out of spiders, like requests, items, exceptions, and start_requests. They do share some basic functionality with downloader middlewares, but they can’t generate requests in response to responses. They stand between the spiders and the downloader. One example is filtering out responses with bad HTTP status codes. Some middlewares can function as either a downloader middleware or a spider middleware, but they’re often trivial and will be forced into one category or the other once you add more complex functionality.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"},{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"}]},{"title":"spdk18.07和dpdk18.08不兼容","slug":"spdk18-07和dpdk18-08不兼容","date":"2018-09-05T07:53:18.000Z","updated":"2018-12-31T11:39:50.000Z","comments":true,"path":"2018/09/05/spdk18-07和dpdk18-08不兼容/","link":"","permalink":"http://yoursite.com/2018/09/05/spdk18-07和dpdk18-08不兼容/","excerpt":"","text":"今天发现SPDK的版本和DPDK版本并不完全兼容，同时期github上发布的版本，两者的兼容性测试是没有做的。 之前在邮件列表上看到有人抱怨SPDK总是还需要外部的DPDK，所以现在最新发布的SPDK里面是已经将DPDK作为子模块包含了，如果要使用自己单独配置的DPDK的话，需要考虑版本兼容性问题，比如你发现编译出的DPDK在SPDK中调用时发生undefined reference，这时候就要思考是不是发生了版本兼容性问题。 今天发现SPDK 18.07和DPDK的18.08不兼容的，根据release描述最新应该兼容到DPDK18.05。 需要更加耐心","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"SPDK-DPDK","slug":"SPDK-DPDK","permalink":"http://yoursite.com/tags/SPDK-DPDK/"}]},{"title":"数据库处理iterator模型的pro和con","slug":"数据库处理iterator模型的pro和con","date":"2018-08-23T08:02:30.000Z","updated":"2018-12-31T05:38:26.000Z","comments":true,"path":"2018/08/23/数据库处理iterator模型的pro和con/","link":"","permalink":"http://yoursite.com/2018/08/23/数据库处理iterator模型的pro和con/","excerpt":"","text":"iterator模型（也叫火山执行引擎）出现的年代，数据库查询处理的时间由IO时间主导，而CPU开销并不是很重要。 对每个作为中间结果或者最终结果生成的元组都要调用next函数 对next的调用通常是一个虚函数，或者函数指针 因此对next调用比普通调用更昂贵，因为虚函数调用会损害现代CPU的分支预测性能。 模型的代码局部性不好，需要复杂的book-keeping 假设对一个压缩的关系进行简单的table扫描，由于元组一次生成一个，table扫描的操作需要记住当前元组在压缩的流中的位置，当需要访问下一个元组时，要跳转到对应的解压缩代码位置。 下面用一个例子展示火山执行引擎的原理： 上图描述了 select id,name,age from people where age >30 的火山模型的查询计划，该查询计划包含 User，Project，Select，Scan 四个 operator，每个 operator 的 next 方法递归调用子节点的 next，一直递归调用到叶子节点 Scan operato，Scan Operator 的 next 从文件中返回一个元组。 火山模型的主要缺点是昂贵的解释开销 (interpretation overhead) 和低下的 CPU Cache 命中率。首先，火山模型的 next 方法通常实现为一个虚函数，在编译器中，虚函数调用需要查找虚函数表, 并且虚函数调用是一个非直接跳转 (indirect jump), 会导致一次错误的 CPU 分支预测 (branch mis-prediction), 一次错误的分支预测需要十几个周期的开销。火山模型为了返回一个元组，需要调用多次 next 方法，导致昂贵的函数调用开销。研究表明，在采用火山执行模型的 MySQL 中执行 TPC-H Q1 查询，仅有 10% 的时间用于真正的查询计算，其余的 90% 时间都浪费在解释开销 。其次，next 方法一次只返回一个元组，元组通常采用行存储，如图 Row Format，如果顺序访问第一列 1，2，3，那么每次访问都将导致 CPU Cache 命中失败 (假设该行不能完全放入 CPU Cache 中)。如果采用 Column Format，那么只有在访问第一个值时才出现缓存命中失败，后续访问 2 和 3 时都将缓存命中成功, 从而极大的提高查询性能。","categories":[],"tags":[{"name":"databases","slug":"databases","permalink":"http://yoursite.com/tags/databases/"},{"name":"查询优化","slug":"查询优化","permalink":"http://yoursite.com/tags/查询优化/"}]},{"title":"Playing with meson and ninja in building DPDK","slug":"Playing-with-meson-and-ninja-in-building-DPDK","date":"2018-06-15T01:45:46.000Z","updated":"2018-12-31T11:39:40.000Z","comments":true,"path":"2018/06/15/Playing-with-meson-and-ninja-in-building-DPDK/","link":"","permalink":"http://yoursite.com/2018/06/15/Playing-with-meson-and-ninja-in-building-DPDK/","excerpt":"","text":"首先，下面报错code cc: error: unrecognized command line option &#39;-march=native&#39;-march在530上没有实现，于是直接定义mcpu ./zglbuild/meson-private/libdpdk.pc:Cflags: -I${includedir} -I${includedir} -include rte_config.h -march=native这里","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"SPDK-DPDK","slug":"SPDK-DPDK","permalink":"http://yoursite.com/tags/SPDK-DPDK/"},{"name":"SW64","slug":"SW64","permalink":"http://yoursite.com/tags/SW64/"}]},{"title":"内联汇编中的指针内存访问","slug":"内联汇编中的指针内存访问","date":"2018-06-14T08:48:05.000Z","updated":"2018-12-31T05:38:26.000Z","comments":true,"path":"2018/06/14/内联汇编中的指针内存访问/","link":"","permalink":"http://yoursite.com/2018/06/14/内联汇编中的指针内存访问/","excerpt":"","text":"unsigned long addr=m(\\addr)注意，这时取到的并不是addr的值，而是括号和*号抵消了，将addr作为地址去取数据。","categories":[{"name":"技术","slug":"技术","permalink":"http://yoursite.com/categories/技术/"}],"tags":[{"name":"内联汇编","slug":"内联汇编","permalink":"http://yoursite.com/tags/内联汇编/"}]},{"title":"学会提问","slug":"学会提问","date":"2017-08-16T02:22:01.000Z","updated":"2018-12-31T11:05:13.000Z","comments":true,"path":"2017/08/16/学会提问/","link":"","permalink":"http://yoursite.com/2017/08/16/学会提问/","excerpt":"","text":"四个问题要回答自己 我有没有问“为什么”别人要我相信他的观点 在我想到别人的说法可能有问题时有没有把它记录下来 我对别人说过的话有没有进行客观评价 针对某一特定主体，我有没有在别人合理说法的基础上形成自己的结论","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"读书","slug":"读书","permalink":"http://yoursite.com/tags/读书/"}]},{"title":"巨流河读书笔记","slug":"巨流河读书笔记","date":"2017-08-16T02:21:46.000Z","updated":"2018-12-31T11:04:28.000Z","comments":true,"path":"2017/08/16/巨流河读书笔记/","link":"","permalink":"http://yoursite.com/2017/08/16/巨流河读书笔记/","excerpt":"","text":"这本书讲了一个国民党家庭从松花江畔，几经辗转最后到了台湾的故事，反映了民国时一代人的生活轨迹，有些悲戚，不是很看的进去。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"u\\*\\_t是什么","slug":"u-t是什么","date":"2017-07-20T01:34:21.000Z","updated":"2018-12-31T11:39:09.000Z","comments":true,"path":"2017/07/20/u-t是什么/","link":"","permalink":"http://yoursite.com/2017/07/20/u-t是什么/","excerpt":"","text":"因为你会涉及到跨平台，不同的平台会有不同的字长，所以利用预编译和typedef可以让你最有效的维护你的代码。按照posix标准，一般整形对应的*_t类型为：1字节 uint8_t2字节 uint16_t4字节 uint32_t8字节 uint64_t","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"c","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"配置ConnectX-3 DPDK","slug":"配置ConnectX-3-DPDK-1","date":"2017-07-20T01:33:53.000Z","updated":"2018-12-31T11:02:23.000Z","comments":true,"path":"2017/07/20/配置ConnectX-3-DPDK-1/","link":"","permalink":"http://yoursite.com/2017/07/20/配置ConnectX-3-DPDK-1/","excerpt":"","text":"By default, the EAL creates hugepage files on each hugetlbfs filesystem using the rtemap_X filename, where X is in the range 0 to the maximum number of hugepages -1. Similarly, it creates shared configuration files, memory mapped in each process, using the /var/run/.rte_config filename, when run as root (or $HOME/.rte_config when run as a non-root user; if filesystem and device permissions are set up to allow this). The rte part of the filenames of each of the above is configurable using the file-prefix parameter.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"SPDK-DPDK","slug":"SPDK-DPDK","permalink":"http://yoursite.com/tags/SPDK-DPDK/"}]},{"title":"配置ConnectX-3 DPDK","slug":"配置ConnectX-3-DPDK","date":"2017-07-17T08:02:40.000Z","updated":"2018-12-31T11:02:15.000Z","comments":true,"path":"2017/07/17/配置ConnectX-3-DPDK/","link":"","permalink":"http://yoursite.com/2017/07/17/配置ConnectX-3-DPDK/","excerpt":"","text":"安装Install MLNX_OFED_验证固件版本高于2.36.5000###./dpdk-devbind.py –status ./dpdk-devbind.py -b igb_uio 0000:03:00.0_","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"SPDK-DPDK","slug":"SPDK-DPDK","permalink":"http://yoursite.com/tags/SPDK-DPDK/"}]},{"title":"shared\\_ptr智能指针","slug":"shared-ptr智能指针","date":"2017-07-13T08:00:06.000Z","updated":"2018-12-31T11:38:48.000Z","comments":true,"path":"2017/07/13/shared-ptr智能指针/","link":"","permalink":"http://yoursite.com/2017/07/13/shared-ptr智能指针/","excerpt":"","text":"boostshared_ptr 本身不是 100% 线程安全的。它的引用计数本身是安全且无锁的，但对象的读写则不是_","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"Clion结合GitHub进行版本控制","slug":"Clion结合GitHub进行版本控制","date":"2017-07-12T14:03:49.000Z","updated":"2018-12-31T11:38:30.000Z","comments":true,"path":"2017/07/12/Clion结合GitHub进行版本控制/","link":"","permalink":"http://yoursite.com/2017/07/12/Clion结合GitHub进行版本控制/","excerpt":"","text":"基本的三步走，add commit push首先要链接Clion到github，也就是给Clion配置你自己的github账户","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"使用Clion重构","slug":"使用Clion重构","date":"2017-07-12T08:33:05.000Z","updated":"2018-12-31T11:01:28.000Z","comments":true,"path":"2017/07/12/使用Clion重构/","link":"","permalink":"http://yoursite.com/2017/07/12/使用Clion重构/","excerpt":"","text":"Refactorings in CLion ▪ Rename (Shift+F6) renames symbols, automatically correcting all references in the code for you.▪ Change Signature (Ctrl+F6 on Windows/Linux, Cmd+F6 on OS X) helps you add/remove/reorder function parameters, change the result type or update the name of the function, all usages will be fixed as well.▪ Move (F6) moves files or directories, as well as methods, variables or constants.▪ Copy (F5) allows you to create a copy of file or directory.▪ Safe Delete (Alt+Delete on Windows/Linux, Cmd+Delete Forward on OS X) safely removes files and symbols from your code. ▪ Inline (Ctrl+Alt+N on Windows/Linux, Alt+Cmd+N on OS X) replaces redundant variable usage/method calls with its initializer/declaration.▪ Extract refactoring – CLion analyses the block of code where the refactoring was invoked, detects input and output variables, together with the usages of the selected expression to replace them with the newly created:▪ Variable (Ctrl+Alt+V on Windows/Linux, Alt+Cmd+V on OS X)▪ Constant (Ctrl+Alt+C on Windows/Linux, Alt+Cmd+C on OS X)▪ Parameter (Ctrl+Alt+P on Windows/Linux, Alt+Cmd+P on OS X)▪ Typedef (Ctrl+Alt+K on Windows/Linux, Alt+Cmd+K on OS X)▪ Define (Ctrl+Alt+D on Windows/Linux, Alt+Cmd+D on OS X)▪ Method (Ctrl+Alt+M on Windows/Linux, Alt+Cmd+M on OS X)▪ Superclass▪ Subclass▪ Pull Members Up safely moves class members to a superclass.▪ Push Members Down safely moves class members to a subclass.You can use Refactor This (Ctrl+Alt+Shift+T on Windows/Linux, Ctrl+T on OS X) to get the list of the refactorings available in the current scope.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"c","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"etcd使用","slug":"etcd使用","date":"2017-07-11T11:16:31.000Z","updated":"2018-12-31T11:38:05.000Z","comments":true,"path":"2017/07/11/etcd使用/","link":"","permalink":"http://yoursite.com/2017/07/11/etcd使用/","excerpt":"","text":"etcd 是一个高可用的分布式 key-value(键值) 存储系统。在暴漫我们用他用来做配置管理和服务发现。项目中使用etcd进行共享目录DirectoryClient get_hostname register_server refresh_server get_server_list get_server_info unregister_server","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://yoursite.com/tags/分布式系统/"}]},{"title":"intel DPDK","slug":"intel-DPDK","date":"2017-07-10T14:58:55.000Z","updated":"2018-12-31T11:37:18.000Z","comments":true,"path":"2017/07/10/intel-DPDK/","link":"","permalink":"http://yoursite.com/2017/07/10/intel-DPDK/","excerpt":"","text":"http://dpdk.org/doc/guides/prog_guide/overview.html","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"SPDK-DPDK","slug":"SPDK-DPDK","permalink":"http://yoursite.com/tags/SPDK-DPDK/"}]},{"title":"cmake使用","slug":"cmake使用","date":"2017-07-10T13:24:01.000Z","updated":"2018-12-31T11:36:45.000Z","comments":true,"path":"2017/07/10/cmake使用/","link":"","permalink":"http://yoursite.com/2017/07/10/cmake使用/","excerpt":"","text":"PROJECT(XXX) 工程名SET(CMAKE_CXX_COMPILER g++-5)SET设置一个变量的值SET(LIBRARIES ${LIBRARIES} rt numa pthread)SET(LIBRARIES ${LIBRARIES} curl) SET(LIBRARIES ${LIBRARIES} boost_coroutine boost_system)多个选项之间用空格隔开-—INCLUDE_DIRECTORIES(${CMAKE_SOURCE_DIR}/src) Add the given directories to those the compiler uses to search for include filesADD_DEFINITIONS(-std=c++14) 为源文件的编译添加由-D定义的标志。MESSAGE(STATUS “Debugging is disabled (to enable, run cmake .. -DDEBUG=ON)”)SET_SOURCE_FILES_PROPERTIES(src/mica/util/siphash/siphash24.c PROPERTIES LANGUAGE CXX) Set properties associated with source files using a key/value paired list. See properties documentation for those known to CMake. Unrecognized properties are ignored. Source file properties are visible only to targets added in the same directory (CMakeLists.txt).ADD_EXECUTABLE(test_table src/mica/test/test_table.cc ${SOURCES})修改CMAKE","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"cmake","slug":"cmake","permalink":"http://yoursite.com/tags/cmake/"}]},{"title":"reinterpret\\_cast的用法","slug":"reinterpret-cast的用法","date":"2017-07-09T12:15:23.000Z","updated":"2018-12-31T11:36:30.000Z","comments":true,"path":"2017/07/09/reinterpret-cast的用法/","link":"","permalink":"http://yoursite.com/2017/07/09/reinterpret-cast的用法/","excerpt":"","text":"The reinterpret_cast operator also allows any integral type to be converted into any pointer type and vice versa. Misuse of the reinterpret_cast operator can easily be unsafe. Unless the desired conversion is inherently low-level, you should use one of the other cast operators.这个操作符允许任何整数类型被转换为任何指针类型。如果使用错误，这个操作符很容易导致不安全。除非你需要的转换是在底层进行的，否则建议使用其他的cast操作符。 The reinterpret_cast operator can be used for conversions such as char* to int*, or One_class* to Unrelated_class*, which are inherently unsafe.这个操作符可以用来从char*到int* 或者从一个class*到另一个不相关的class * The result of a reinterpret_cast cannot safely be used for anything other than being cast back to its original type. Other uses are, at best, nonportable.The reinterpret_cast operator cannot cast away the const, volatile, or __unaligned attributes. See const_cast Operator for information on removing these attributes. The reinterpret_cast operator converts a null pointer value to the null pointer value of the destination type._ One practical use of reinterpret_cast is in a hash function, which maps a value to an index in such a way that two distinct values rarely end up with the same index._ 一个实践中的例子是在hash函数中使用这个操作符，把一个值映射到一个索引。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"读未来简史有感","slug":"读未来简史有感","date":"2017-07-09T08:36:59.000Z","updated":"2018-12-31T11:00:51.000Z","comments":true,"path":"2017/07/09/读未来简史有感/","link":"","permalink":"http://yoursite.com/2017/07/09/读未来简史有感/","excerpt":"","text":"这本书用科技对自由意志的冲击这个主题，串起来了很多有意思的段子。 经颅直流电刺激，这个词听着就很刺激，简单看了一下Sally dee的刺激实验结果，感觉未来的增强人类很恐怖。 冷水实验通过分析人们对冷水实验的反应，提炼出人判断事情的基本原则，即叙事自我,体验自我，我们对经历过的事情会总结成一个叙事自我，通常这个叙事自我对一件事情的定义是取一个感受的最大值。也就是说，会记得最痛苦的地方和最快乐的地方。 自由主义不过是幻想，我们的孩子不能白死。这是说付出越多，越不舍得放弃。 23AndMe，这是一个基因公司，99刀就能测试癌症基因，还算便宜哈哈。 Facebook的300赞预测，通过你点过的300个赞，脸书就能知道你是什么样的人，对事情做什么样的判断。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"What's new in Linux Kernel 4.12","slug":"What-s-new-in-Linux-Kernel-4-12","date":"2017-07-08T14:10:22.000Z","updated":"2018-12-31T11:36:21.000Z","comments":true,"path":"2017/07/08/What-s-new-in-Linux-Kernel-4-12/","link":"","permalink":"http://yoursite.com/2017/07/08/What-s-new-in-Linux-Kernel-4-12/","excerpt":"","text":"Disk / File-Systems:Two new I/O schedulers make things exciting in the block layer. The BFQ (Budget Fair Queueing) finally landed in mainline as well as the Facebook-developed Kyber I/O scheduler. I’ve already done some SSD Linux 4.12 I/O scheduler tests while more benchmarks (including on HDDs) will be done soon.XFS support for GETFSMAP, a new ioctl for returning space mapping information. EXT4 also picked up GETFSMAP support as well as some performance tuning/fixes.Btrfs meanwhile has some long-awaited RAID 5/6 fixes.The F2FS flash file-system has seen various optimizations and fixes.Also noteworthy are more MD RAID optimizations.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"内核","slug":"内核","permalink":"http://yoursite.com/tags/内核/"}]},{"title":"为什么要用zeromq","slug":"为什么要用zeromq","date":"2017-07-03T04:03:44.000Z","updated":"2018-12-31T11:00:38.000Z","comments":true,"path":"2017/07/03/为什么要用zeromq/","link":"","permalink":"http://yoursite.com/2017/07/03/为什么要用zeromq/","excerpt":"zeromq作为加强型的socket，已经被用于很多大规模分布式系统的开发中，这里记录一下自己的思考，为什么要用zeromq。要回答这个问题，首先要谈到的是，zeromq是什么，下面这个在zeromq的guide中的图清楚显示了这个概念。借用云风大神的话来说，它就是”比 tcp 协议更高一级的协议”，并且“改变了通讯都基于一对一的连接这个假设”。 zeromq中的通讯模式有四种， Request-reply, which connects a set of clients to a set of services. This is a remote procedure call and task distribution pattern. Pub-sub, which connects a set of publishers to a set of subscribers. This is a data distribution pattern. Pipeline, which connects nodes in a fan-out/fan-in pattern that can have multiple steps and loops. This is a parallel task distribution and collection pattern. Exclusive pair, which connects two sockets exclusively. This is a pattern for connecting two threads in a process, not to be confused with “normal” pairs of sockets.要弄懂这些模式，首先要看函数 zmq_socket的手册页初始化一个zmq的上下文context首先要调用zmq_socket，void *zmq_socket (void *context, int type);","text":"zeromq作为加强型的socket，已经被用于很多大规模分布式系统的开发中，这里记录一下自己的思考，为什么要用zeromq。要回答这个问题，首先要谈到的是，zeromq是什么，下面这个在zeromq的guide中的图清楚显示了这个概念。借用云风大神的话来说，它就是”比 tcp 协议更高一级的协议”，并且“改变了通讯都基于一对一的连接这个假设”。 zeromq中的通讯模式有四种， Request-reply, which connects a set of clients to a set of services. This is a remote procedure call and task distribution pattern. Pub-sub, which connects a set of publishers to a set of subscribers. This is a data distribution pattern. Pipeline, which connects nodes in a fan-out/fan-in pattern that can have multiple steps and loops. This is a parallel task distribution and collection pattern. Exclusive pair, which connects two sockets exclusively. This is a pattern for connecting two threads in a process, not to be confused with “normal” pairs of sockets.要弄懂这些模式，首先要看函数 zmq_socket的手册页初始化一个zmq的上下文context首先要调用zmq_socket，void *zmq_socket (void *context, int type); 对于上面提到的四个模式，每个模式都有对应的不同的type来用来初始话一个zmq的socket.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://yoursite.com/tags/分布式系统/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"20170501","slug":"20170501","date":"2017-05-01T13:22:29.000Z","updated":"2018-12-31T11:35:44.000Z","comments":true,"path":"2017/05/01/20170501/","link":"","permalink":"http://yoursite.com/2017/05/01/20170501/","excerpt":"","text":"？？？这一天干了什么？","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"Coding RDMA [2]","slug":"Coding-RDMA-2","date":"2016-12-30T11:53:30.000Z","updated":"2018-12-31T11:42:13.000Z","comments":true,"path":"2016/12/30/Coding-RDMA-2/","link":"","permalink":"http://yoursite.com/2016/12/30/Coding-RDMA-2/","excerpt":"","text":"两个相关资源You can look at the ping-pong examples that come with libibverbs.http://www.openfabrics.org/downloads/libibverbs/Also you can look at the performance tests (ib_write_lat, ib_write_bw, etc).http://www.openfabrics.org/downloads/perftest/ rdma_rc_example.c输入 -p port -d ib-dev -i ib-port -g gid-idx","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"RDMA","slug":"RDMA","permalink":"http://yoursite.com/tags/RDMA/"},{"name":"网络","slug":"网络","permalink":"http://yoursite.com/tags/网络/"}]},{"title":"Coding RDMA [1]","slug":"Coding-RDMA-1","date":"2016-12-29T14:53:04.000Z","updated":"2018-12-31T11:34:49.000Z","comments":true,"path":"2016/12/29/Coding-RDMA-1/","link":"","permalink":"http://yoursite.com/2016/12/29/Coding-RDMA-1/","excerpt":"","text":"RDMA provides Channel based IOIn traditional sockets networks, applications request network resources from the operating system through an API which conducts the transaction on their behalf. However RDMA use the OS to establish a channel and then allows applications to directly exchange messages without further OS intervention Compare with TCP/IP When an application wants to send a packet, the OS places the bytes into an anonymous buffer in main memory belonging to the operating system and when the byte transfer is complete, the OS copies the data in its buffer into the receive buffer of the application. This process is repeated each time a packet arrives until the entire byte stream is received. TCP is responsible for retransmitting any lost packets due to congestion. In IB, a complete message is delivered directly to an application. Once an application has requested transport of an RDMA Read or Write, the IB hardware segments the outbound message as needed into packets whose size is determined by the fabric path maximum transfer unit. These packets are transmitted through the IB network and delivered directly into the receiving application’s virtual buffer where they are re-assembled into a complete message. The receiving application is notified once the entire message has been received. Thus neither the sending nor the receiving application is involved until the entire message is delivered into the receiving application’s buffer. RDMA-Aware Programming在执行RDMA操作之前，首先要建立与远程主机的连接，以及设定一些权限。这些事情由QP（Queue Pair）完成。在连接的两端都要建立QP，Communication Manager会在实际QP建立之前交换QP的信息。一旦QP建立完成，RDMA verb API（RDMA reads, RDMA writes, and atomic operations.）就可以用了。 Transport Modes当设置QP的时候，有很多传输模式可以选择，包括四类，UD UC RD UC RC 可靠连接 QP只和一个其他的QP相关联，由一个QP的发送队列传输的信息被传输到对应的QP的接收队列。数据包有序传输 UC 不可靠连接 一个QP只和一个其他的QP相关联，连接不可靠，数据包可能丢失。如果发送的信息出现错误，将不会重传，错误的处理必须依靠高一层的协议完成。 UD 不可靠数据报文 一个QP可以向任意一个其他的QP接受和发送报文。数据包的顺序不保证，已经收到的数据包也可能会被发送方放弃掉。 关键部件Send Request (SR)SR定义数据怎么发送，从哪里发送，到哪里。struct ibv_send_wr用来实现SR Receive Request (RR)一个RR会定义一个buffer，对于非RDMA操作的数据会被接收并且存储在这里。如果在有传输方发送了一个send请求或者RDMA write请求时没有buffer，接收方会发送一个receive not ready (RNR) error，struct ibv_recv_wr实现了RR。 Completion QueueMemory Registration 允许应用定义一些连续虚存区域的集合，或者一些连续物理地址区域的集合，然后把这个集合交给网络适配器，作为一个虚拟地址连续的buffer。 这个注册过程会将内存页pin在内存中不会被操作系统换出。 在注册过程中，操作系统检查注册了的块的权限，并且注册进程会把虚实地址映射表写入到网络适配器中。 当注册内存时，会对内存区域设置权限，这些权限包括，local write, remote read, remote write, atomic, and bind 每个内存区域MR有一个本地key和一个远程key。(r_key, l_key). 本地key由本地的HCA使用，来访问本地的内存，比如在一个receive操作中。远程key由远程HCA使用，允许远程进程通过RDMA操作访问系统内存。 相同的内存区域可以被多次注册（即便是权限不一样），并且每次注册得到的key都不一样。 struct ibv_mr 被用来实现内存注册_- Memory Window内存窗口允许应用对目标是它的内存远程访问有更加灵活的控制，主要面向一下几个场景： 应用想要使用动态的方式，用更小的开销授予或者撤销远程访问对一个已经注册了的内存区域的访问权限 wants to grant different remote access rights to different remote agents and/or grant those rights over different ranges within a registered Region.把一个内存窗口和一个内存区域关联起来的操作叫做binding不同的内存窗口可能重叠相同的MRAddress Vector地址向量是用来描述从本地节点到远程节点的路由的对象每个UC/RC QP 都有一个地址向量在QP上下文当中对于UD QP，对于每个post SR都要定义一个地址向量struct ibv_ah is used to implement address vectors._ Typical Application两个例子， RDMA RC例子，使用VPI verbs API，证明如何执行RC: Send, Receive, RDMA Read and RDMA Write operations. 多播的例子，使用RDMA_CM verbs API, _demonstrating Multicast UD. 主要结构如下 拿到设备列表. 首先你要拿到本地机器中可用IB的列表，这个列表中的每个设备都包含了一个名字和一个GUID，例如设备名字可能是： mthca0, mlx4_1._ 打开请求了的设备循环访问设备列表，根据GUID或者设备名字来打开它 查询设备功能设备功能允许打开了的设备支持的特性 (APM, SRQ)和功能 分配保护域（Protection Domain）来包含你的资源一个保护域允许用户来约束哪些部件可以和哪些部件进行交互，这些部件可能是AH, QP, MR, MW, and SRQ 注册一个内存区域VPI只能在注册了的内存上工作，进程地址空间中的任何内存Buffer都可以被注册。在注册过程中，用户设置内存权限并且获得本地与远程keys,这些key会被后来用于访问内存buffer 创建一个完成队列Completion Queue (CQ);一个CQ包含了完成了的工作请求 work requests (WR)，每个WR会生成一个完成队列项 completion queue entry (CQE)，这个项会被放在CQ中，每个CQE会指出WR完成的成功与否。 创建一个QP创建一个QP同时也会创建相关联的发送队列和接收队列 启动一个QP创建了的QP必须经过几个状态转换才能被使用，最终达到 Ready To Send (RTS)状态。这些提供了QP用来传输与接收数据的必要信息。具体例子见文档1. 发送工作请求并且查询等待使用创建了的QP来进行通讯操作。 Cleanup Destroy objects in the reverse order you created them: Delete QP Delete CQ Deregister MR Deallocate PD Close device","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"RDMA","slug":"RDMA","permalink":"http://yoursite.com/tags/RDMA/"},{"name":"网络","slug":"网络","permalink":"http://yoursite.com/tags/网络/"}]},{"title":"20161228","slug":"20161228","date":"2016-12-28T01:56:53.000Z","updated":"2018-12-31T11:35:23.000Z","comments":true,"path":"2016/12/28/20161228/","link":"","permalink":"http://yoursite.com/2016/12/28/20161228/","excerpt":"","text":"这一天也不知道干了啥………………","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20161226","slug":"20161226","date":"2016-12-26T12:24:42.000Z","updated":"2018-12-31T11:34:12.000Z","comments":true,"path":"2016/12/26/20161226/","link":"","permalink":"http://yoursite.com/2016/12/26/20161226/","excerpt":"","text":"安装完毕执行/etc/init.d/openibd restart这时ib进入初始化阶段/etc/init.d/opensmd start这时进入active状态 infinibandibping 0x1ibstatmount node-1.rdma:/home/zgl/HERD /home/zgl/HERDopensmosmtestibaddr /etc/init.d/opensm startimphugepages-create.sh 0 4096hugepages-create.sh 1 4096","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"},{"name":"RDMA","slug":"RDMA","permalink":"http://yoursite.com/tags/RDMA/"}]},{"title":"2016121","slug":"2016121","date":"2016-12-21T01:11:32.000Z","updated":"2018-12-31T11:34:06.000Z","comments":true,"path":"2016/12/21/2016121/","link":"","permalink":"http://yoursite.com/2016/12/21/2016121/","excerpt":"","text":"总结 数据流系统这个概念很难理解","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20161213","slug":"20161213","date":"2016-12-13T09:54:59.000Z","updated":"2018-12-31T11:34:01.000Z","comments":true,"path":"2016/12/13/20161213/","link":"","permalink":"http://yoursite.com/2016/12/13/20161213/","excerpt":"","text":"2","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"专注力","slug":"专注力","date":"2016-12-07T12:35:59.000Z","updated":"2018-12-31T10:59:37.000Z","comments":true,"path":"2016/12/07/专注力/","link":"","permalink":"http://yoursite.com/2016/12/07/专注力/","excerpt":"","text":"今天开始看专注力这本书，这里先起个头。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"20161207","slug":"20161207","date":"2016-12-07T12:02:17.000Z","updated":"2018-12-31T11:33:55.000Z","comments":true,"path":"2016/12/07/20161207/","link":"","permalink":"http://yoursite.com/2016/12/07/20161207/","excerpt":"","text":"今天还是买了得到APP的两个课程，李笑来的《通往财富自由之路》和万维钢的《精英日课》，突然发现我还是一个很爱钱的人，哈哈。万维钢的两个文章比较有意思，一个是关于为什么人们从心理上更倾向于使用信用卡消费，并且在使用信用卡消费的时候会消费很多的。这个文章提到了一个消费痛感的概念，就是说通常我们在用信用卡消费的时候痛感较低，而在用现金或者其他方式进行消费的时候痛感则更高。比如我们如果吃薯片，如果同样的量，买了很多小包的和买了一个大包的，通常买了很多小包的人会吃更少的薯片。我可以利用这个心理改掉自己的很多不好的习惯。另外一个是关于难得糊涂，有时候我们充分准备，非常详尽，反而不如草草准备来的效果好，这就是过度拟合现象。这个概念来自《指导生活的算法：人类决策中的心理学》，想要避免这个过犹不及的现象，这个书中给出了三个建议。 限定思考时间。 一天时间内必须完成报告，或者一个小时内必须完成会议，在一定时间限制下，才会逼着自己去考虑重要的事情 限定内容长度。要求下属写报告不超过一张纸。如果一个方案一张纸不能解释清楚，那就应该放弃这个方案。另一个方法是电梯谈话，在电梯到达前说清楚方案。 使用粗马克笔，在白板上讨论商业计划。 最初的计划必须要抓住重点，笔画越粗，对你的思维越有利，越能逼着你思考大局。 今天其实也发生了很多事情，最近在考虑下一步课题应该做什么，花了三天的时间去看docker的代码，发现每个版本的改动都比较大，可读性并不好，常常让我弄不清楚在做什么，现在在系统研究中去做docker有关的研究，时间成本太高了，可能是不能够接受的。现在时间这么紧张，最好是做一些发明轮子的工作。我想就从内核中DMA的实现开始着手，如果真的完全脱离了对CPU的占用，那么NVM作为全局内存的实现是可以完成的。 也发生了一些糟糕的事情，我不太能够很好控制自己的情绪，今天和飞飞差点吵起来，跑步的时候，今天也跑的很慢，总之并不是很顺利。 最好的事情，是我回归了，慢慢学会总结一些东西，把时间放在那些自己已经在做的事情上，并且在这些事情上花更多的时间，这样才能够成功。 我相信我是可以的。加油！加油！","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"golang","slug":"golang","date":"2016-12-04T05:14:26.000Z","updated":"2018-12-31T11:33:49.000Z","comments":true,"path":"2016/12/04/golang/","link":"","permalink":"http://yoursite.com/2016/12/04/golang/","excerpt":"","text":"golang是谷歌推出的语言，他们的广告词是简单，可靠，高效的语言。为什么要用golang呢，借用知乎上的回答，主要有下面几点。 部署简单，Go编译生成的是一个静态可执行文件，除了glib外没有其他的外部依赖，这样部署很方便。 并发性好，Goroutine和channel使得编写高并发的服务器端软件变得相当容易，很多情况下完全不需要考虑锁机制以及由此带来的各种问题。单个Go应用能够有效的利用CPU多核，并行执行的性能好。 良好的语言设计。虽然Go不支持很多高级语言特性，但是go的规范简单灵活，工程上很适合。同时Go自带了完善的工具链。 执行性能好，虽然不如C和java，但是比python还是高一个数量级。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"整体性学习","slug":"整体性学习","date":"2016-11-27T12:46:15.000Z","updated":"2018-12-31T10:59:19.000Z","comments":true,"path":"2016/11/27/整体性学习/","link":"","permalink":"http://yoursite.com/2016/11/27/整体性学习/","excerpt":"","text":"今天读完了整体性学习这本书，这里简单总结一下 在整体性学习中主要三大概念，结构，模型以及高速公路。与传统的学习方法相比，整体性学习强调对信息之间的关系进行强调，用多种方式表达信息，使得我们能够在需要使用信息的时候能够更快的想到。通过建立信息之间的关系，达到了加强记忆效果，加深理解的作用，同时强调对学习到的信息进行高效利用。书中提到了很多之前没有接触过的学习方法，比如如何更好的记笔记，如何指读法，如何积极阅读法，怎样用内在化，比喻，联想法，怎样处理信息，同时，书中还对个人的管理提出了很多实用的建议，对我个人触动比较大的就是首先保证睡眠，然后批处理也是非常好的概念，生活上，要把所有物品都放在固定的位置，这一点我做的很不好。然后每周读一本书这个我勉强才能完成。书中提到了指定计划的方法，要把计划指定的需要努力才能完成。比如每周读完一本书这类的目标。总之，这本书给我带来的收获是不少的，我把这本书的组织结构想象成了一个人的消化过程，首先进行吸收，获取知识，然后消化，理解知识，然后营养进入血液，拓展，然后让我们更强壮，应用。当然这个消化过程是通用的，但是一些具象化的方法，以及一些小的技巧都是非常值得学习的，希望能够对我将来的学习带来一个很好的提升。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"docker概览","slug":"docker概览","date":"2016-11-24T12:33:07.000Z","updated":"2018-12-31T11:33:41.000Z","comments":true,"path":"2016/11/24/docker概览/","link":"","permalink":"http://yoursite.com/2016/11/24/docker概览/","excerpt":"","text":"","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"container","slug":"container","permalink":"http://yoursite.com/tags/container/"}]},{"title":"cgroups memory management","slug":"cgroups-memory-management","date":"2016-11-12T06:06:51.000Z","updated":"2018-12-31T11:27:14.000Z","comments":true,"path":"2016/11/12/cgroups-memory-management/","link":"","permalink":"http://yoursite.com/2016/11/12/cgroups-memory-management/","excerpt":"","text":"https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txthttp://events.linuxfoundation.org/sites/events/files/slides/Efficient_Memory_Management_on_Mobile_Devices_0.pdf","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"http://yoursite.com/tags/内存管理/"},{"name":"container","slug":"container","permalink":"http://yoursite.com/tags/container/"}]},{"title":"20161109","slug":"20161109","date":"2016-11-09T01:53:02.000Z","updated":"2018-12-31T11:29:31.000Z","comments":true,"path":"2016/11/09/20161109/","link":"","permalink":"http://yoursite.com/2016/11/09/20161109/","excerpt":"","text":"以后slack合作的时候，工作的时候再调整成在线状态。时间观念，每天用一张纸，记录自己做什么事情的时间，看看时间都花在哪里了知乎专栏？抄写代码 重新画图 重新做实验，加入对DRAM的对比实验 EveningAmazing things that happened today. 发现了提升实验的目标并且实现了 合作越来越融洽了How could today have been even better? 早起一些，早点吃好饭","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20161108","slug":"20161108","date":"2016-11-08T04:47:56.000Z","updated":"2018-12-31T11:29:47.000Z","comments":true,"path":"2016/11/08/20161108/","link":"","permalink":"http://yoursite.com/2016/11/08/20161108/","excerpt":"","text":"MorningI am grateful for 早上没有睡懒觉 . . What would make today great?Daily affirmations, I am: 与大牛讨论论文的写作 开通了知乎专栏，关于云计算的论文阅读 EveningAmazing things that happened today.How could today have been even better?","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20161103","slug":"20161103","date":"2016-11-03T05:36:25.000Z","updated":"2018-12-31T11:29:51.000Z","comments":true,"path":"2016/11/03/20161103/","link":"","permalink":"http://yoursite.com/2016/11/03/20161103/","excerpt":"","text":"问题一文章主要解决两个问题，这两个问题，我们提出的两个机制分别作了哪些改进不同机制解决不同问题。 问题二Introduction中we believe这一段不要过多描述，每个人对问题理解不同。 问题三main contribution分别为 解决思路方法一 解决思路方法二 设计系统问题四mode switching 变成几句话 问题五每个实验分开写一个大点，要写出实验是怎么做的，解释直观的实验现象，再说明实验分析出的原因，和设计结合来讲。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"The Nuts and Bolts of Writing Papers","slug":"The-Nuts-and-Bolts-of-Writing-Papers","date":"2016-10-30T13:51:51.000Z","updated":"2018-12-31T11:33:10.000Z","comments":true,"path":"2016/10/30/The-Nuts-and-Bolts-of-Writing-Papers/","link":"","permalink":"http://yoursite.com/2016/10/30/The-Nuts-and-Bolts-of-Writing-Papers/","excerpt":"Papers are your primary work products as a researcher, so it’s in your interest to make sure they are of high quality. This document describes the practical aspects of writing papers. It details your responsibilities in the process (depending on your role) and what you need to do and when. This includes many small, non-obvious details (e.g., checking in a copy of the reviews to svn) that make our lives easier before, during, and after the paper deadline.作为研究人员，文章是我们主要的产品，所以我们的兴趣点就是确认","text":"Papers are your primary work products as a researcher, so it’s in your interest to make sure they are of high quality. This document describes the practical aspects of writing papers. It details your responsibilities in the process (depending on your role) and what you need to do and when. This includes many small, non-obvious details (e.g., checking in a copy of the reviews to svn) that make our lives easier before, during, and after the paper deadline.作为研究人员，文章是我们主要的产品，所以我们的兴趣点就是确认This document covers the practical side of writing papers. Its contents fall into two categories: 1) Useful hints for making the paper writing process go smoothly and 2) expectations for what needs to be done to produce a high quality paper. This second category is especially important because it helps make sure we are all the same page about the paper writing process, who’s responsible for what, etc. If you have any questions about anything in this document please ask.This document does not discuss how to structure a paper, craft a good introduction, or create a well-reason argument that flows well and is engaging to the reader. Those are skills I will help you develop as we craft the text and you will continue to hone those skills for your entire carreer. The idea behind this document is get the easy, mechanical stuff out of the way quickly so you can focus your time on learning how to write.","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"写作","slug":"写作","permalink":"http://yoursite.com/tags/写作/"}]},{"title":"20161030","slug":"20161030","date":"2016-10-29T23:16:10.000Z","updated":"2018-12-31T11:30:14.000Z","comments":true,"path":"2016/10/30/20161030/","link":"","permalink":"http://yoursite.com/2016/10/30/20161030/","excerpt":"读书心得最近读完了两本书，一本是《虚无的十字架》，一本是《shoedog》。读东野圭吾的书总有一种静静的讲故事的感觉，像是寒冷的冬夜坐在桌子边，可以听到窗外雪被行人走过，压出吱吱的声音。","text":"读书心得最近读完了两本书，一本是《虚无的十字架》，一本是《shoedog》。读东野圭吾的书总有一种静静的讲故事的感觉，像是寒冷的冬夜坐在桌子边，可以听到窗外雪被行人走过，压出吱吱的声音。而鞋狗这本书，却是讲述了一个漫长的，商业，友谊，生活三者交织的故事。可以从中学到一个人的奋斗与坚持，一个人要想成功必须面临的困境，如何从事业和家庭中找到平衡，如何和朋友，同事相处，以及让别人认可你是多么的重要。特别是对我来说，需要吸取的还很多。有的时候建立很好的第一印象很重要，但是更重要的是要持续的维持很好的伙伴关系，这个很难，并不只是提高自己这么简单。下面准备开始的三本书，一个是《浮士德》，一个是《当下的力量》，然后是《慢思考》。《浮士德》faust是一个博士。。。好粉刺，发现我看的前面这一部分就是各种诗歌对白，有点难懂，但是坚持每天看10分钟，应该能啃下来。 生涯规划这里引用陈皓老师博客最近的一段话： 从去年我从阿里离开到现在14个月了，这段时间内，我给大约40多家公司做过相应的技术咨询和解决过很多技术问题，绝大多数公司都是因为性能和稳定性的问题来找我的，我给这些公司解决问题的时候，基本都是这样的Pattern：一开始，发现都是一些技术知识点的问题，然后，马上进入到系统架构方面方面的问题，当再解决架构问题的时候，我发现，已经是软件工程的问题，而软件工程问题的后面，又是公司管理上的问题而公司管理的问题，结果又到了人的问题上而人的问题，又到了公司文化的问题…… 要做好一个性能高，稳定性好的大规模系统，要在技术、工具、工程、运维、人员几个方面下功夫。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"nohup","slug":"nohup","date":"2016-10-29T23:15:27.000Z","updated":"2018-12-31T11:25:38.000Z","comments":true,"path":"2016/10/30/nohup/","link":"","permalink":"http://yoursite.com/2016/10/30/nohup/","excerpt":"","text":"常常想要在离开实验室之后还能运行一些程序，所以查阅了一些网站，发现了一个有意思的命令https://www.ibm.com/developerworks/cn/linux/l-cn-nohup/ nohup当用户注销或者网络断开时，终端会收到HUP(hangup)信号从而关闭所有子进程。因此解决办法就有两种途径：要么让进程忽略HUP信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程、","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"20161028","slug":"20161028","date":"2016-10-28T02:22:53.000Z","updated":"2018-12-31T11:30:31.000Z","comments":true,"path":"2016/10/28/20161028/","link":"","permalink":"http://yoursite.com/2016/10/28/20161028/","excerpt":"不要因为一份工作、专业甚至职业而安定下来，一定要寻求内心的冲动。即使你不知道其中的含义，也要坚持追寻。如果你追随自己内心的冲动，将会更能忍受疲惫，每一次失望都会成为你的动力，需要攀登的高峰也会变得微不足道起来。那些破除陈规着、创新者和反叛者后背上都有一个靶子，他们越是成功，就越容易受到别人攻击。相信自己，也要相信命运。不是别人的命运，不是你自己定义的命运，而是你内心，对命运的自我定义。","text":"不要因为一份工作、专业甚至职业而安定下来，一定要寻求内心的冲动。即使你不知道其中的含义，也要坚持追寻。如果你追随自己内心的冲动，将会更能忍受疲惫，每一次失望都会成为你的动力，需要攀登的高峰也会变得微不足道起来。那些破除陈规着、创新者和反叛者后背上都有一个靶子，他们越是成功，就越容易受到别人攻击。相信自己，也要相信命运。不是别人的命运，不是你自己定义的命运，而是你内心，对命运的自我定义。 如何阅读商业图书二八原则80%的精华可能只占20%的页码 集中优势精力原则特定时间段内，集中突破20%的精华内容，也可以在一个时间段内，集中攻克一个主题的阅读 递进原则高效率的阅读不一定要按照页码顺序展开，可以挑选自己感兴趣的部分阅读，再从兴趣点扩散到其他部分。切忌贪多，从一个小主题开始，先培养自己的阅读能力，了解文字风格、观点阐述以及案例叙述的方法，目的在于对方法的掌握，这才是最重要的。 好为人师原则在朋友圈中主导、控制话题，引导话题想自己设计的方向去发展，可以让读书收获更加扎实、实用、有效。 阅读方法和阅读习惯养成（1） 回想常常不会一口气读完，第二次拿起书时，至少用15分钟回想上次阅读的内容，不要翻看，实在想不起来再翻看。严格训练自己，一定要回想，坚持50次，会逐渐养成习惯。 （2） 做笔记不要试图让笔记具有很强的逻辑性和系统性，不需要有深刻的见解和思想，只要是文字，就是对大脑的锻炼。在空白处多写多画，随笔、符号、涂色、书签、便签、折页、甚至拆书都可以。 （3） 读后感和PPT坚持写读后感可以大幅度提高阅读能力，做PPT可以提高逻辑分析能力。从写读后感开始，写上五篇之后，再尝试做PPT。连续做上五个PPT，再重复写上三次读后感。如此坚持，阅读能力会大幅提高。 (4) 思想的超越要养成上述阅读习惯，通常需要六个月的严格训练，至少完成四本书的阅读。你会慢慢发现，自己的思想开始跳脱出来，开始有了超越作者的感觉。比拟作者、超越作者、试图凌驾于作者之上开始思考问题，是阅读能力提高的必然结果。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"modpaper","slug":"modpaper","date":"2016-10-24T13:03:34.000Z","updated":"2018-12-31T11:25:55.000Z","comments":true,"path":"2016/10/24/modpaper/","link":"","permalink":"http://yoursite.com/2016/10/24/modpaper/","excerpt":"","text":"主要问题 摘要不要太复杂，第一句说背景，第二句第三句说问题，挑战，第四句写设计了什么，后面两句话概括实验 intro中讲故事，用大白话讲通过有意义，和相关工作一起写 introduction后面介绍贡献的总结，打点介绍，这样更加清晰。介绍文章的组织结构。 不要用太多的缩写词，第一次最好写全称。 后面引入的时候要重新写 小标题的起名要有一个连接关系，递进关系，最好有个别词是一样的。否则会感觉松散。或者在一大节前面介绍这几个小节介绍了什么东西。 参考文献方面，网址减少，更多经典文献。 45合分别精简 7写2也 重点7.2 7.1太多 至少两页 测试程序介绍 7.2性能 功耗 功效分解 改字词 Rethinking DRAM Power Modes for Energy Proportionality这篇文章指出静态功耗占比达到了60%70%","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"写作","slug":"写作","permalink":"http://yoursite.com/tags/写作/"}]},{"title":"bookmark1021","slug":"bookmark1021","date":"2016-10-20T22:38:29.000Z","updated":"2018-12-31T11:27:38.000Z","comments":true,"path":"2016/10/21/bookmark1021/","link":"","permalink":"http://yoursite.com/2016/10/21/bookmark1021/","excerpt":"","text":"书摘《世界观，现代年轻人必懂的科学哲学与科学史》这本书是一个关于科学史和科学哲学的著作，主要分三个部分，一是介绍科学史和科学哲学的一些基本问题，二是探索亚里士多德世界观到牛顿世界观的转变，三是探索近代发展，特别是相对论，量子理论和演化论对西方世界观带来的挑战。 《怎样写好一个故事》这本书是由91篇非虚构故事的写作者的一些经验之谈组成的，整本书分为九章，简单翻看一下，我觉得这本书里面的文章质量参差不齐，有的文章信息量不大，讲述的是大家都知道的知识，幸运的是还有部分文章是值得一读的。 重视观念的重要性，培养将观念和故事结合的技能有关服装，装饰以及口音的身份细节—社会经济学地图上戏剧中的场景概念—从人物的角度引用很多会话","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"20161020","slug":"20161020","date":"2016-10-20T10:56:21.000Z","updated":"2018-12-31T11:30:46.000Z","comments":true,"path":"2016/10/20/20161020/","link":"","permalink":"http://yoursite.com/2016/10/20/20161020/","excerpt":"","text":"新书入库 沈复的《浮生六记》 —满满的闲情逸致啊 哈佛非虚构写作课 怎样讲好一个故事 —简单翻了一下，收录很多著名菲叙事类新闻的作者的一些见闻感触 STL源码解析— 侯捷的大作，简单翻看了一下，整个书的结构都是很用心的。 世界观，现代年轻人必懂的科学哲学与科学史 虚无的十字架— 又买了东野圭吾的书，自从我妈上次说喜欢看这种书，就一直计划着买，结果书却选错了地址，我要看的寄回了家，买给她的却来了我这里，不过可能也得排队在很久之后看了。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"related works how to","slug":"related-works-how-to","date":"2016-10-17T09:02:53.000Z","updated":"2018-12-31T11:33:22.000Z","comments":true,"path":"2016/10/17/related-works-how-to/","link":"","permalink":"http://yoursite.com/2016/10/17/related-works-how-to/","excerpt":"写在前面很多人都会遇到更有经验的对手，也许我根本没有可能赢。但是如果我迈出脚步，鼓起勇气，最后累晕，对手仍然打败了我，只要我让对手紧张起来，让他竭尽全力才能赢我，那么这只证明当天他的表现比我好。— 史蒂夫 普雷方丹 tips 每次读一篇文章的时候，对这篇文章做一个短小的总结，同时注意到一些重要章节的亮点。这样你就能够通过阅读自己的评论来确定是否可用。 当阅读一篇文章的时候，阅读它的相关工作，如果这篇文章与你的题目相关度非常高，那么很可能这篇文章引用的文章也和你的题目非常相关，你也有必要阅读这些文章。 仔细阅读你要提交的目标期刊之前刊登的文章，可能你会找到与你的题目相关的文章。 当为一个文章写一个段落的时候，确定你能够回答，这篇文章是怎么和我的工作相关的这个问题，如果不能回答，就不要包含它在你的文章中。","text":"写在前面很多人都会遇到更有经验的对手，也许我根本没有可能赢。但是如果我迈出脚步，鼓起勇气，最后累晕，对手仍然打败了我，只要我让对手紧张起来，让他竭尽全力才能赢我，那么这只证明当天他的表现比我好。— 史蒂夫 普雷方丹 tips 每次读一篇文章的时候，对这篇文章做一个短小的总结，同时注意到一些重要章节的亮点。这样你就能够通过阅读自己的评论来确定是否可用。 当阅读一篇文章的时候，阅读它的相关工作，如果这篇文章与你的题目相关度非常高，那么很可能这篇文章引用的文章也和你的题目非常相关，你也有必要阅读这些文章。 仔细阅读你要提交的目标期刊之前刊登的文章，可能你会找到与你的题目相关的文章。 当为一个文章写一个段落的时候，确定你能够回答，这篇文章是怎么和我的工作相关的这个问题，如果不能回答，就不要包含它在你的文章中。 Farming当把你的研究放在已有的文章中间，并不需要显示别人的工作都是错了，然后来显示你的工作是对的。应当专注在描述你的工作是怎么建立在前人的已有知识上，并且提供了额外的insight。写相关工作的时候，就像你在告诉你引用文章的作者，你的工作提供了什么。一篇文章的贡献毕竟是有限的，尽管你的目标是通过你的研究改变世界，你不可能通过一篇文章做到这些，所以在写contribution的时候不要过于夸大自己。当你叙述你使用“这是我们知道的第一个工作”这样的叙述的时候要谨慎，如果我看到这样的话题，通常会进行很多相关工作的搜索。如果没有其他人，很可能有相似工作，但是你没有采用。相反的，如果你在阅读相关工作的时候，遇到了和你研究的课题解决相同问题的时候，不要害怕。在理想的世界中可能在你开始你的研究之前，就已经识别所有相关工作，这样就能帮助你的研究，但是实际情况不是这样的。但是有可能不了解的不全面，并且相关工作可能在你开始过程中发生。然而这其实通常是一个好事，这意味着其他人也对你的课题有兴趣，这样你就能够有一个新的观察问题的视角。对于任何问题来说有很大的弓箭可以研究，你的工作会有机会做出贡献，唯一的挑战就是找出这个贡献是什么，并且怎么清楚的告诉你的读者。由于审稿人会从你引用的文章作者中选取，引用那些你希望review你工作的人的文章。审稿人喜欢通过看你的引文列表来看你引用的完全性，有时会用来确认他们写作的文章被引用了，为了避免伤害他们的自尊心，不要留下明显的漏洞，尝试引用大量不同作者的工作。 如果相关的话，可以引用你自己的文章，尽管你写的文章是被匿名提交的。没不要匿名这些引用。相反，就像引用其他人的文章一样引用你的文章，使用第三人称。举个例子在一篇文章的跨领域研究中我写到”Teevan et al. 32 showed, via query log analysis, that nearly 40% of queries were attempts to re-find previously encountered results.” 但是尽管可以引用你自己的工作，注意不要夸大自己。 Structure典型的相关工作遵从一下基本结构: 它由一些通用领域的overview的句子开始， 然后评估特别相关，要深入讨论的领域 章节的结构由几个段落构成，每个段落讨论一个相关研究分支的情况 这个章节有一个总结段落结束，这个段落总结这篇文章在已有工作的基础上做出的贡献。 相关工作的第一个段落应该帮助一个有相关知识的读者把这篇文章放在一个分类中。注意同时是不能太泛泛而谈。要专注特定的子领域，告诉读者那部分子领域是特别相关的。 在相关工作章节的主体部分，不要只是列举段落，每个总结一个相关的文章。总结讷讷狗狗帮助你为自己构建一个整体的图形。然而在相关工作的部分，你需要帮助你的读者组织与分类已有的研究工作，每个自然段的起始句子用来描述为什么在这个段落中套路你的文章是相关的，引用所有关键点相关的文章。然后写一两句关于两个或者几个最相关的文章，强调他们使用的方法或者相关的发现。最后段落结束用一句话总结你文章中的工作在这些文章的启发下，做出了哪些贡献。 An example of this basic structure for a paragraph in the body of a Related Work section can be found in A Crowd-Powered Socially Embedded Search Engine: Overview of the papers in this paragraph: SNS question asking has been studied in many contexts, including on Facebook (Lampe et al., 2012; Morris et al., 2010; Panovich et al., 2012; Teevan et al., 2011), on Twitter (Efron and Winget, 2010; Java et al., 2007; Li et al., 2011; Paul et al., 2011), in the enterprise (Thom et al., 2011), and across cultures (Yang et al., 2011; Liu &amp; Jansen, 2013).Sentences about relevant papers:Morris et al. (2010) found most questions posted to social network sites are subjective, seeking recommendations and opinions.Paul et al. (2011) showed many are also rhetorical, with the asker expecting social answers rather than informative ones.The prevalence of subjective and rhetorical questions on social network sites has been a challenge for socially embedded search engines like SearchBuddies (Hecht et al., 2012), a Facebook agent that algorithmically suggests URLs in response to questions.How this paper contributes: Our crowd-powered system handles these nuanced scenarios because people are kept in the loop.ACM papers use numbers to cite related work, which provides limited context compared to other citation formats. Do not treat these numbers as part of the paper’s text. You should not, for example, say, “In 23 the authors explore …” Instead, write the text as if the numbers weren’t there, saying, “Teevan et al. 23 explore …” 相关工作的总结应该用一个自然段来，总结根据现存的文献，知道了什么并且强调为什么你文章中要展示的工作在这个基础上提供了一个宝贵的贡献。 An example can be found in Understanding How the Projection of Availability State Impacts the Reception of Incoming Communication: In summary, the work presented in this paper builds on previous research to explore how availability information relates to people’s communication decisions. While earlier work focused on how availability information impacts the people initiating communication, we focus on its impact on the decisions of the recipient. Further, we are able to study this behavior at a much larger scale than previously possible by looking at the users of a popular enterprise communication system that infers its users’ availability.","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"写作","slug":"写作","permalink":"http://yoursite.com/tags/写作/"}]},{"title":"20161004","slug":"20161004","date":"2016-10-04T08:39:53.000Z","updated":"2018-12-31T11:31:05.000Z","comments":true,"path":"2016/10/04/20161004/","link":"","permalink":"http://yoursite.com/2016/10/04/20161004/","excerpt":"","text":"需要继续进行wear leveling 的实验，首先的问题是，这个应当描述成热点，还是直接从wear leveling的角度开始说？还是从wear leveling 角度开始实现，如果之前要提到，可以使用这里的数据。然后对qemu进行了扩展，扩展了对写的统计。看了一下会议的分类，适合下面的分类，11月15交abstract 11月22交manuscriptEDA3. Cross-Layer Power Analysis and Low-Power Design• EDA3.1 System-level low-power design and thermal analysis, simulation and management• EDA3.2 Architectural low-power techniques: partitioning, scheduling, and resource management• EDA3.3 Power-aware communication architectures, algorithms and techniques","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20161003","slug":"20161003","date":"2016-10-03T05:56:54.000Z","updated":"2018-12-31T11:31:12.000Z","comments":true,"path":"2016/10/03/20161003/","link":"","permalink":"http://yoursite.com/2016/10/03/20161003/","excerpt":"","text":"Misc看到CSDN上一篇比较CoreOS rkt和docker的文章，我机器上两个都装了，吃完午饭，玩儿了一下，rkt现在还是有一些小问题。 Lessons learned今天看文章的时候，看到很多图，觉得数据很陌生，然后当时画图的时候要表达的意思也模糊了，如果当时画图的时候就把所有的描述工作都做了，就不会有这么多事情，但是画了图又去做其他事情，导致后面再拿起来的时候发生困难，这是非常低效的。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"constructing EPT","slug":"ept","date":"2016-09-28T11:28:41.000Z","updated":"2018-12-31T11:26:43.000Z","comments":true,"path":"2016/09/28/ept/","link":"","permalink":"http://yoursite.com/2016/09/28/ept/","excerpt":"","text":"初始化首先从arch/x86/kvm/mmu.c里面的init_kvm_mmu讲起，这个函数决定了KVM的mmu类型。我们默认打开二维分页tdp_enabled _在这个情况下硬件会遍历两个页表，一个是GVA->GPA的，在遍历这个链表的同时，会遍历GPA->HPA的链表，由于我们的硬件支持，所以不用做shadow paging.，那么init_kvm_tdp_mmu里面看一看，这里注册了很多处理函数，可以看到值得关注的几个函数_ 1. tdp_page_fault nonpaging_sync_page nonpaging_invlpg_ nonpaging_update_pte kvm_inject_page_fault_这几个函数光看名字就很诱惑啦，让人很想搞清楚what r u 弄啥嘞。。。Steps in building EPT 最初guest的CR3寄存器指向的guest物理页面也是空页面 要访问页表的时候发生异常，KVM没有介入处理，而是由guest OS的缺页异常处理函数负责分配一个guest物理页面，然后调用vmx_set_cr3将这个物理地址(GPA)回填，建立guest的页表结构。 当前建立了GVA->GPA, 接下来要GPA->HPA, 也就是EPT的工作，这个时候当前进程的EPT是空的，产生EPT_VOILATION_虚拟机退出到根模式下运行，这里看到vmx.c中的handle_ept_violationhandle_ept_violation|–> kvm_mmu_page_fault_这里r = vcpu->arch.mmu.page_fault(vcpu, cr2, error_code, false);调用上面注册的处理函数|–>tdp_page_fault()-> tdp_page_fault()刷新EPT我们比较关心的就是如何进行刷新EPT找到两个函数ept_sync_global和ept_sync_context： 前者的粒度太大了，是对所有的cpu进行刷新，我们选择使用后者，根据vcpu，就能确定范围，只要指定的vm进行flush ept的操作就行了. vmx_flush_tlb|–> vmx_set_cr3|–> load_vmcs12_host_state_|–> .tlb_flush = vmx_flush_tlb,","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"intel","slug":"intel","permalink":"http://yoursite.com/tags/intel/"}]},{"title":"vswapper","slug":"vswapper","date":"2016-09-27T11:38:32.000Z","updated":"2018-12-31T11:32:49.000Z","comments":true,"path":"2016/09/27/vswapper/","link":"","permalink":"http://yoursite.com/2016/09/27/vswapper/","excerpt":"VSWAPPER: A Memory Swapper for Virtualized Environments","text":"VSWAPPER: A Memory Swapper for Virtualized Environments首先先把ballooning一顿臭骂。。。double paging: the guest kernel attempts to reclaim a page that has already been swapped out by the host, a fact unknown to the guest since it is uncooperative. When such an event occurs, it causes the page contents to be faulted-in from host swap area, only to be immediately written to the guest swap area, generating wasteful IO activity that host/guest cooperation would have obviated. changing load： has varing working set, since prediction of the active working set size is difficult.if the light load is transient and the memory requirement of the workload on the VM suddenly exceed the reduced RAM available, ballooning is insufficiently responsive to instantaneously increase RAM vswapper如何应对动态变化的内存负载的？？？？？paravirtualization: A guest OS is paravirtual if it is modified in a manner that makes it aware it is being virtulized,e.g. by installing hypervisor tools. Comment: 我们需要跟谁比较呢？带来的多余读写，适合的动态响应策略，都是我们像这里的ballooning 一样可以和unmodified system进行比较的优势。 好吧，接下来不骂ballooning了，把原生系统虚拟化的不合作现象一顿臭骂。。。 Silent SwapWrites: So long as memory is plentiful, much of the memory is dedicated to caching file content long after the content is used, in the hope that it will get re-used in the future.Data centers in the wild: A large performance studyin virtual setup with uncooperative swapping, host decide which page to swap, host 没法区分一个被reclaim的页在guest VM中是否是脏的，所以把所有reclaim的页都放到swap区域，指定时间到了就会写回到disk，不管这个页和原来的页是否相同。。。、!!!这个对NVM有影响！！！ 但是也是要在host非常紧张，reclaim了guest的页的情况才存在。 If a victim page is dirty, the host writes it to its swap area so as to later be able to recover the correct data. 这种脏页被写到swap的情况多吗？为什么不直接写回？ Stale Swap Reads: 假设guest显式读了它自己的磁盘块到它自己的内存页P，这个操作会退出到host 对磁盘进行一个物理IO操作，而如果在这个时候，P被host回收了，在这个情况下，在执行这个物理IO之前，host会受到一个page fault,需要从交换swap中fault-in这个页，然而这个fault的处理最终却很快就被新的IO操作给覆盖了.comment：这个情况只有在host没了内存的时候才会出现，一般情况下只要这个页在host的page cache中，就不会出现这个stale swap read的情况。 False Swap Reads： 与上面的陈旧写一样，就是有可能guest请求写的页碰巧被host给reclaim到swap区域了，那么最后搞了半天还是要被很快覆盖。不同的是前面的陈旧写是被磁盘的写覆盖，而这里的false swap read是被CPU的写覆盖。 Decayed Swap Sequentiality: 为了减轻对长时间的磁盘读的等待，OS执行文件预取，一般情况下都是期待顺序的续写 False Page Anonymity： OS喜欢reclaim named pages,因为他们不需要写回到swap，文件访问更适合顺序访问，所以更适合预取。Linux page replacement design 这部分是linux的分析文章。所有磁盘页都被标记为匿名页，随着内存需求增加，开始swap named页， 大熊猫：安静的吃东西，发呆，挠痒痒，在不同的地方挠各种痒痒","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"内存管理","slug":"内存管理","permalink":"http://yoursite.com/tags/内存管理/"},{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"}]},{"title":"Mike Carson","slug":"Mike-Carson","date":"2016-09-26T04:51:20.000Z","updated":"2018-12-31T11:26:06.000Z","comments":true,"path":"2016/09/26/Mike-Carson/","link":"","permalink":"http://yoursite.com/2016/09/26/Mike-Carson/","excerpt":"看HN的时候偶然发现了这个人，Mike Carson，这里就写写他做了什么有意思的东西吧。","text":"看HN的时候偶然发现了这个人，Mike Carson，这里就写写他做了什么有意思的东西吧。他的网站是http://humb.ly/做了一个阅后即焚的文件缓存池，文件上传后一旦下载一次，就会被删除。写着写着发现，这些工作也有一些壁垒，比如 需要web开发经验，通常很多都是web开发从业人员 很多本来就给freelance写了很久代码的人 So 我想还是不太适合我的定位，我要做后端。。。fighting…","categories":[{"name":"生涯思考","slug":"生涯思考","permalink":"http://yoursite.com/categories/生涯思考/"}],"tags":[{"name":"大牛","slug":"大牛","permalink":"http://yoursite.com/tags/大牛/"},{"name":"indie hackers","slug":"indie-hackers","permalink":"http://yoursite.com/tags/indie-hackers/"}]},{"title":"20160923","slug":"20160923","date":"2016-09-23T12:50:37.000Z","updated":"2018-12-31T11:31:29.000Z","comments":true,"path":"2016/09/23/20160923/","link":"","permalink":"http://yoursite.com/2016/09/23/20160923/","excerpt":"","text":"今天和晓强师兄以及方亮聊了一会儿，算下时间，已经不多了，需要赶紧把文章投稿出去了。我的问题是，一直不想要把工程合拢，每次看到新的，好玩的东西，都想要实现以下，那么导致整个工程一直处于开发阶段，从来没有一个定点，告诉自己，开发到这里，以后就不再继续了。今天，我决定把工作合拢，从现在开始进入实验阶段，每个工作就以现在的状态进行实验。。。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160917","slug":"20160917","date":"2016-09-17T02:51:36.000Z","updated":"2018-12-31T11:31:50.000Z","comments":true,"path":"2016/09/17/20160917/","link":"","permalink":"http://yoursite.com/2016/09/17/20160917/","excerpt":"","text":"攀登做的更好的办法就是承担更多的责任。 设法找到没有人愿意涉足的领域，或者一些遗留的应用，将沼泽变成良田。 成为团队中其他人的导师 有些工作没人愿意做，承担并且简化，自动化。 撰写周报，记录活动日志 提供演讲或者培训，督促自己 发表意见， 保证存在感曝光度。 自学，微软认证证书？证明严肃对待自己的职业生涯。不要忘记分享自己学到的东西。可以创建自己的博客，为杂志写文章或者写书，还可以在社区活动或者技术大会上发表演讲。 成为问题的解决者，做看似没有解决不了的障碍的人。不要总是说这个问题太难，那个想法行不通。要成为永远能够为各种问题寻找解决方案的人，要成为用于执行解决方案以获得成果的人。 无法避开政治的时候，至少应该知道会发生什么，哪种人需要避开，哪种人永远不要有交集。 TODO today: 绘制目前对整个迁移过程的了解的总图。流程图。。。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"20160915","slug":"20160915","date":"2016-09-15T14:52:03.000Z","updated":"2018-12-31T11:32:09.000Z","comments":true,"path":"2016/09/15/20160915/","link":"","permalink":"http://yoursite.com/2016/09/15/20160915/","excerpt":"","text":"文明人之所以与野蛮人不同，主要是来自于审慎，或者用一个更广义的名词，即深谋远虑。他为了将来的快乐，哪怕这种将来的快乐是相当遥远的，而愿意忍受目前的痛苦。审慎与热情的冲突是一场贯穿全部历史的冲突。这场冲突中，我们不应完全偏袒任何一方。 哈哈哈，要不要来点巴库斯的热情……","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160913","slug":"20160913","date":"2016-09-13T06:35:58.000Z","updated":"2018-12-31T11:24:53.000Z","comments":true,"path":"2016/09/13/20160913/","link":"","permalink":"http://yoursite.com/2016/09/13/20160913/","excerpt":"","text":"《软技能 代码之外的生存指南》今天又买了一本书，叫做。。。作者在开篇讲了一句触动了我的话，很多程序员最大的错误就是认为自己是在为别人工作，很少人会自己去管理自己的职业生涯。希望能够从这本书中学到对自己生涯的管理，怎么对未来进行规划和选择。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160911","slug":"20160911","date":"2016-09-11T16:17:38.000Z","updated":"2018-12-31T11:24:48.000Z","comments":true,"path":"2016/09/12/20160911/","link":"","permalink":"http://yoursite.com/2016/09/12/20160911/","excerpt":"","text":"空空如也……","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160902","slug":"20160902","date":"2016-09-02T16:22:37.000Z","updated":"2018-12-31T11:24:32.000Z","comments":true,"path":"2016/09/03/20160902/","link":"","permalink":"http://yoursite.com/2016/09/03/20160902/","excerpt":"","text":"回到宿舍，放下包，看着空荡的宿舍，我突然间有一种面对自己的感觉，突然间感觉我站在第三人称的某个视角，看着现在的自己，也突然间感觉到，我是如此的幸福。今天得知了彪哥最新的病情，骨髓纤维化，这样的病在普通人身上千万分之一的概率，而他如此近的发生在我身边，发生在仿佛前一阵子还一起玩耍，一起打球的人身上。人世间的那些快乐和悲伤当由于某种原因，这个pod被调度到新的机器上，就会触发新一次的exchg","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"qemu中的thread, bh以及coroutine的用法","slug":"qemu中的thread-bh以及coroutine的用法","date":"2016-08-30T15:23:21.000Z","updated":"2018-12-31T11:24:10.000Z","comments":true,"path":"2016/08/30/qemu中的thread-bh以及coroutine的用法/","link":"","permalink":"http://yoursite.com/2016/08/30/qemu中的thread-bh以及coroutine的用法/","excerpt":"","text":"qemu_thread_create(&amp;iothread->thread, thread_name, iothread_run, 95: iothread, QEMU_THREAD_JOINABLE); qemu_thread_join(&amp;iothread->thread); qemu_notify_bh = qemu_bh_new(notify_event_cb, NULL); qemu_bh_schedule(qemu_notify_bh);qemu_bh_delete(pool->completion_bh);_","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"coroutine","slug":"coroutine","permalink":"http://yoursite.com/tags/coroutine/"}]},{"title":"20160829","slug":"20160829","date":"2016-08-29T11:26:33.000Z","updated":"2018-12-31T11:23:38.000Z","comments":true,"path":"2016/08/29/20160829/","link":"","permalink":"http://yoursite.com/2016/08/29/20160829/","excerpt":"","text":"看了云风的博客，我才发现技术博客不应当是大量的代码，而应该是很多自己的思考，其实真正有价值的是对问题的判断和认知过程，具体代码并不重要。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"postcopy page fault handling","slug":"postcopy-page-fault-handling","date":"2016-08-25T13:42:35.000Z","updated":"2018-12-31T11:23:19.000Z","comments":true,"path":"2016/08/25/postcopy-page-fault-handling/","link":"","permalink":"http://yoursite.com/2016/08/25/postcopy-page-fault-handling/","excerpt":"","text":"在postcopy的过程中，如果target vm访问了一个没有被传输的页面，那么这个页面就会触发page fault，从而从源VM拷贝数据。这个过程在下面这个函数中完成。https://www.youtube.com/watch?v=2VNswMRT6JQ 1","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"内存迁移","slug":"内存迁移","permalink":"http://yoursite.com/tags/内存迁移/"}]},{"title":"How to add qemu option by defining a xml","slug":"How-to-add-qemu-option-by-defining-a-xml","date":"2016-08-24T07:37:02.000Z","updated":"2018-12-31T11:23:03.000Z","comments":true,"path":"2016/08/24/How-to-add-qemu-option-by-defining-a-xml/","link":"","permalink":"http://yoursite.com/2016/08/24/How-to-add-qemu-option-by-defining-a-xml/","excerpt":"","text":"The \\qemu:commandline\\ domain XML tagThere is a special namespace for QEMU-specific tags in libvirt domain XML. Youcannot use QEMU-specific tags without first declaring the namespace. To enableit use the following:\\&lt;domain type=’kvm’ xmlns:qemu=’http://libvirt.org/schemas/domain/qemu/1.0&#39;\\&gt; Now you can add command-line arguments to the QEMU invocation. For example, to load an option ROM with-option-rom:\\qemu:commandline\\ \\&lt;qemu:arg value=’-option-rom’/> \\&lt;qemu:arg value=’path/to/my.rom’/>\\&lt;/qemu:commandline> It is also possible to add environment variables to the QEMU invocation:\\qemu:commandline\\ \\&lt;qemu:env name=’MY_VAR’ value=’my_value’/>\\&lt;/qemu:commandline>","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"}]},{"title":"page relocation scheme","slug":"page-relocation-scheme","date":"2016-08-24T03:18:18.000Z","updated":"2018-12-31T11:22:49.000Z","comments":true,"path":"2016/08/24/page-relocation-scheme/","link":"","permalink":"http://yoursite.com/2016/08/24/page-relocation-scheme/","excerpt":"","text":"I name the process as page relocation rather than page swap just to differentiate it from the page swapping in virtual memory concept.We use post copy method to do page relocation so that the VM has a minimal downtime than precopy, in which the migration will take a lot of time depending on the workload and page dirtying rate of the VM. TODO: 确定迁移是否停止VM的执行。 在vl.c中，首先创建fd handler or bh or thread来完成启动region migration的操作。参考migration.c中的实现，","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"内存迁移","slug":"内存迁移","permalink":"http://yoursite.com/tags/内存迁移/"}]},{"title":"migration","slug":"migration","date":"2016-08-23T16:15:05.000Z","updated":"2018-12-31T11:22:29.000Z","comments":true,"path":"2016/08/24/migration/","link":"","permalink":"http://yoursite.com/2016/08/24/migration/","excerpt":"qemu的迁移，可以通过tcp连接，也可以通过libvirt的RPC,但是核心的机制应该是相同的。","text":"qemu的迁移，可以通过tcp连接，也可以通过libvirt的RPC,但是核心的机制应该是相同的。12345678910111213141516171819202122232425262728293031323334353637383940//迁移发起端：hmp-commands.hx|—\\&gt; hmp\\_migrate\\_|—\\&gt;qmp\\_migrate//入口函数qmp\\_migrate（migration.c）qmp\\_migrate |--\\&gt; migrate\\_init |--\\&gt; ? tcp\\_start\\_outgoing\\_migration |--\\&gt; ? rdma\\_start\\_outgoing\\_migration |--\\&gt; ? exec\\_start\\_outgoing\\_migration |--\\&gt; ? exec\\_start\\_outgoing\\_migration |--\\&gt; ? unix\\_start\\_outgoing\\_migration |--\\&gt; ? fd\\_start\\_outgoing\\_migration |--\\&gt; exec\\_start\\_outgoing\\_migration* |--\\&gt; migration\\_channel\\_connect\\_ \\* |--\\&gt; migrate\\_fd\\_connect|--\\&gt; rdma\\_start\\_outgoing\\_migration* |--\\&gt; ? migrate\\_fd\\_connect * |--\\&gt; ? migration\\_thread * |--\\&gt; ? qemu\\_savevm\\_state\\_iterate//这是源VM上的主迁移线程qemu\\_savevm\\_state—\\&gt; qemu\\_savevm\\_state\\_iterateqemu\\_savevm\\_state\\_iterate调用注册savevm\\_ram\\_handler* |—\\&gt; ram\\_save\\_iterateram\\_save\\_iterate* |—\\&gt; ram\\_find\\_and\\_save\\_block * |—\\&gt;ram\\_save\\_host\\_page * |—\\&gt;ram\\_save\\_target\\_page\\_ * |—\\&gt; ram\\_save\\_page * |—\\&gt; ram\\_control\\_save\\_page\\_ram\\_save\\_target\\_page\\_//检查是否是脏页，如果是的话，继续调用ram\\_save\\_page保存这个页。ram\\_save\\_page//把给定的页发送到流，调用ram\\_control\\_save\\_page//返回值是写出的页的数目，ram\\_control\\_save\\_page\\_//调用QEMUFile注册的save\\_page回调函数\\_ 保存VM时和内存有关的处理函数在下面这个结构中定义：123456789static SaveVMHandlers savevm\\_ram\\_handlers = &#123;.save\\_live\\_setup = ram\\_save\\_setup,.save\\_live\\_iterate = ram\\_save\\_iterate,.save\\_live\\_complete\\_postcopy = ram\\_save\\_complete,.save\\_live\\_complete\\_precopy = ram\\_save\\_complete,.save\\_live\\_pending = ram\\_save\\_pending,.load\\_state = ram\\_load,.cleanup = ram\\_migration\\_cleanup,&#125;; 在视频中标记为三个阶段第一阶段：mark all ram dirty这个在ram_save_setup中实现，第二阶段：持续发送在上次iterate之后的脏页，这个在ram_save_iterate中实现。第三阶段：停止guest, 传输剩余的脏RAM页，设备状态。这个在migration_thread中实现_ 然而最近出现一些新问题：随着内存总量的增加，需要迁移的内存量增大了，这样第二个阶段就会变得很慢随着vCPU的增加，guest的产生脏页的速度也变慢了，这样同样会导致第二个阶段变得很慢。这些新问题的解决，目前qemu采用了以下几个手段 autoconverge: 停止几个vcpu的执行，保证页被弄脏的速度小于迁移的速度。 xzble： 基于异或数据压缩传输机制，用一个cache记录上次迭代发送的数据，把需要第二次迁移的同一个页做一个匹配，只发送这个页的区别，而不是发送整个页。即在cache中对同一个页做匹配。这样一个4KB的页只需要发送几个字节就可以。 migration thread：qemu的设计就是两个线程，一个是占用CPU执行客户指令的，另一个是IO线程，迁移也是在这个IO线程中启动的，在新的设计中，迁移过程在io线程之外，这样客户就能够和这个迁移线程进行交互，从而知道迁移了多少数据，这样客户就能知道迁移中正在发生什么 migration bitmap: 原来每个页要用1B，现在只用1bit","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"内存迁移","slug":"内存迁移","permalink":"http://yoursite.com/tags/内存迁移/"}]},{"title":"backend developer","slug":"backend-developer","date":"2016-08-23T02:44:48.000Z","updated":"2018-12-31T11:21:50.000Z","comments":true,"path":"2016/08/23/backend-developer/","link":"","permalink":"http://yoursite.com/2016/08/23/backend-developer/","excerpt":"","text":"看一下cabernets大神Brendan Burns的简历，高亮的那一段最重要，在之前就为了google的搜索做后端，很多人都向上层去做，我认为根据我的条件和经历，我适合做后端。 Partner ArchitectMicrosoftJuly 2016 – Present (2 months)Working on Azure Resource Manager and other related Azure Cloud services. Senior Staff Software EngineerGoogleJune 2008 – July 2016 (8 years 2 months)Greater Seattle AreaLead engineer on Kubernetes, Google’s open source cluster manager for Docker containers. Previously technical lead and manager for the other APIs in the Google Cloud Platform, including Google Deployment Manager and Cloud DNS. Prior to working on the Google Cloud Platform, I was tech. lead for a Search Infrastructure team developing some of the backends that power Google Web Search as well as Google Plus search. Assistant ProfessorUnion CollegeSeptember 2006 – June 2008 (1 year 10 months)Develop and teach new course work in Computer Science, Robotics and Studio ArtSoftware EngineerThomson FinancialSeptember 1999 – September 2000 (1 year 1 month)","categories":[{"name":"生涯思考","slug":"生涯思考","permalink":"http://yoursite.com/categories/生涯思考/"}],"tags":[{"name":"decisions","slug":"decisions","permalink":"http://yoursite.com/tags/decisions/"}]},{"title":"diffrerentOSes","slug":"diffrerentOSes","date":"2016-08-22T03:12:14.000Z","updated":"2018-12-31T11:20:52.000Z","comments":true,"path":"2016/08/22/diffrerentOSes/","link":"","permalink":"http://yoursite.com/2016/08/22/diffrerentOSes/","excerpt":"","text":"其实这些不能算是下一代操作系统，而是云操作系统。 https://cloudbase.it/qemu-img-windows/OSvhttps://github.com/cloudius-systems/osv/wiki/Running-OSv-image-under-KVM-QEMU https://www.youtube.com/watch?v=FKc0lFaPzXA&amp;feature=youtu.be https://groups.google.com/forum/#!topic/osv-dev/sbmyxE9B9V8 coreOShttps://coreos.com/os/docs/latest/booting-with-qemu.html","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"OSv","slug":"OSv","permalink":"http://yoursite.com/tags/OSv/"},{"name":"next generation OS","slug":"next-generation-OS","permalink":"http://yoursite.com/tags/next-generation-OS/"}]},{"title":"material","slug":"material","date":"2016-08-20T12:21:22.000Z","updated":"2018-12-31T11:20:08.000Z","comments":true,"path":"2016/08/20/material/","link":"","permalink":"http://yoursite.com/2016/08/20/material/","excerpt":"","text":"PCM将PCM单元暴露在0.5THz电流下几个皮秒就能构成晶态，并且晶态纤维可以可靠的测量，这能够用于存储数据，尽管这个单元的大部分还是非晶态。而现在DRAM工作在ns级别，http://news.stanford.edu/press/view/9468 A thousandfold increase in speed coupled with lower energy use suggests a path toward future memory technologies that could far outperform anything previously demonstrated","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"NVM","slug":"NVM","permalink":"http://yoursite.com/tags/NVM/"}]},{"title":"zmalloc","slug":"zmalloc","date":"2016-08-19T13:51:34.000Z","updated":"2018-12-31T10:58:06.000Z","comments":true,"path":"2016/08/19/zmalloc/","link":"","permalink":"http://yoursite.com/2016/08/19/zmalloc/","excerpt":"","text":"malloc—&gt;sbrkmalloc allocates memory on the heap, period.Your C library typically keeps a list (or some more intricate data structure) of available memory chunks, finding a suitable chunk to satisfy a malloc (possibly splitting a larger chunk into a number of smaller ones) and returning free’d memory to the list (possibly merging a few smaller chunks into a bigger one)Only when the list doesn’t contain a large enough chunk to satisfy your malloc, the library will ask the OS for more memory, e.g. using the sbrk syscall. sbrk strace -c ls 现在基本可以认定，redis的zmalloc最终调用sbrk，然而在这个情形下，我们可以记录zmalloc得到的地址序列，分析命中的位置， 继续仔细分析redis的详细内存增长，是以什么样的粒度进行分配的，主要使用了哪个内存分配机制。 tcmalloc中的内存分配机制，在它的内存分配机制中，引入对读写均衡度的考量。明天要看一下在使用tcmalloc的时候，主要使用了哪个队列。 tcmalloc tcmalloc为每个线程分配了线程局部的cache，小分配就都是子啊这种线程局部的cache中完成， 12345678910inline void\\* do\\_malloc\\_no\\_errno(size\\_t size) &#123; if (ThreadCache::have\\_tls &amp;&amp; LIKELY(size \\&lt; ThreadCache::MinSizeForSlowPath())) &#123;return do\\_malloc\\_small(ThreadCache::GetCacheWhichMustBePresent(), size); &#125; else if (size \\&lt;= kMaxSize) &#123;return do\\_malloc\\_small(ThreadCache::GetCache(), size); &#125; else &#123;return do\\_malloc\\_pages(ThreadCache::GetCache(), size); &#125;&#125; small cache分配 123456789101112131415inline void* do\\_malloc\\_small(ThreadCache* heap, size\\_t size) &#123; ASSERT(Static::IsInited()); ASSERT(heap != NULL); size\\_t cl = Static::sizemap()-\\&gt;SizeClass(size); size = Static::sizemap()-\\&gt;class\\_to\\_size(cl); if ((FLAGS\\_tcmalloc\\_sample\\_parameter \\&gt; 0) &amp;&amp; heap-\\&gt;SampleAllocation(size)) &#123;return DoSampledAllocation(size); &#125; else &#123;// The common case, and also the simplest. This just pops the// size-appropriate freelist, after replenishing it if it's empty.return CheckedMallocResult(heap-\\&gt;Allocate(size, cl)); &#125;&#125; tc_malloc_stats输出在tcmalloc中，小对象在per-thread的cache中进行分配，大对象在page heap中进行分配，图中可以看出per-thread cache的大小从8B、16B到13KB.实际上tcmalloc为小对象创建了86个大小的size classes。 要想弄懂，主要看下面这个实验，上面申请的是256KB+8B的块，总共申请了200MB，下面的实验中，我们申请256KB-8B的块。可以看出790个span，每个31个8KB的页， 和期望不符合的一点是class 86的obj数目只有36个，do_malloc_stats —&gt;PrintStats —&gt;DumpStats","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"内存分配","slug":"内存分配","permalink":"http://yoursite.com/tags/内存分配/"},{"name":"malloc","slug":"malloc","permalink":"http://yoursite.com/tags/malloc/"},{"name":"sbrk","slug":"sbrk","permalink":"http://yoursite.com/tags/sbrk/"},{"name":"tcmalloc","slug":"tcmalloc","permalink":"http://yoursite.com/tags/tcmalloc/"}]},{"title":"暑假有意义的一件事","slug":"暑假有意义的一件事","date":"2016-08-19T13:51:34.000Z","updated":"2018-12-31T10:59:06.000Z","comments":true,"path":"2016/08/19/暑假有意义的一件事/","link":"","permalink":"http://yoursite.com/2016/08/19/暑假有意义的一件事/","excerpt":"","text":"暑假没有离开学校，没有色彩斑斓的旅行笔记可以分享，只有枯坐宿舍的时候看的几本闲书。作为一个生在新疆的汉族，犹太人对我来说，一直是一个神秘而有趣的民族，假期偶然看到这么一本书《我的应许之地：以色列的悲情与荣耀》，于是就拿来翻了一下，我一直喜欢看喜剧故事，这本书却是个开放结尾。最初对以色列的了解是小时候偶然听人讲过的圣经故事，那时候觉得犹太人就是受害者，摩西带着犹太人出埃及。然而在这本书中，我看到的是现在犹太人复国的喜悦，哈罗德山谷的崛起，吕大城中对巴勒斯坦人驱逐，七日战争。。。然而正如这本书的书名一样，现在的以色列，不过是出在这个悲喜轮回的光明一面，对巴勒斯坦人的不公平，似乎就像一个镜子，反射着几千年前希伯来人的悲惨经历。看完这本书的那天，我突然有些可怜这个民族，突然有人来敲门，“看电影吗？斯皮尔伯格导演的。。。”阿西吧。。。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"WeeklySum-2016-8-3","slug":"WeeklySum-2016-8-3","date":"2016-08-19T11:20:06.000Z","updated":"2018-12-31T11:19:35.000Z","comments":true,"path":"2016/08/19/WeeklySum-2016-8-3/","link":"","permalink":"http://yoursite.com/2016/08/19/WeeklySum-2016-8-3/","excerpt":"","text":"在周五的晚上，一个人坐在队值日的床上，突然想起来承诺自己很久的周总结没有做，心血来潮翻出了这一周的旧账，给自己算算有什么得失吧。近期以来自省非常的多，不知道什么时候大脑中被拨动了一个开关，让自己更多关注自己作为一个人和一般人的区别，和所崇拜的人的差距。这一周最大的事情，莫过于找老板申请的到了一个小型万兆以太网的使用权。并且从14号开始申请以及部署，到18号，所有的数据和代码就已经到位了。下一步就是要进行实验。对自己最不满意的地方，就是在论文写作方面，我突然间发现我在论文写作上面做出的规划太多，而实际完成的又很少，总是在大框架上列出很多条条框框，然后真正落实到文章中的又很少，这样导致文章的写作效率非常低。其实在科研中，我有时会觉得自己写着写者冒出一些idea，然后做着做着又做得偏了，又去修正写的过程，我不太清楚这样是不是我方法的问题，但是我常常会遇到这样的迭代循环，让我不知所措。 基本上这周的工作，就是在假设环境，后半周主要精力集中在寻找合适的benchmark上，我之前主要考虑的使用VMware提供的一些benchmark.主要能用的就是三个，specjbb,kernbench,eclipse。然后我再寻找更多的benchmark。方向就是YCSB和Cloudsuite.我发现自己很容易分心，在做benchmark的同时又去弄了kubernetes和docker，然后还看了osv和coreos。虽然可能和下一个课题有关，但是这样总是分散是不好的！！！再次回到课题上，在分析了redis的内存轨迹之后，我发现基本上没有释放内存，就是一旦分配就一直在使用，即便VM关闭之后，redis也没有马上释放内存。所以说这些内存都是在使用着的。那么问题来了，实际情况是redis是采用自己的malloc机制zmalloc.c文件中。 http://blog.qiji.tech/archives/7854","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"周志","slug":"周志","permalink":"http://yoursite.com/tags/周志/"}]},{"title":"mem usage plot analysis","slug":"mem-usage-plot-analysis","date":"2016-08-19T10:28:04.000Z","updated":"2018-12-31T11:19:06.000Z","comments":true,"path":"2016/08/19/mem-usage-plot-analysis/","link":"","permalink":"http://yoursite.com/2016/08/19/mem-usage-plot-analysis/","excerpt":"","text":"","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"http://yoursite.com/tags/内存管理/"}]},{"title":"kernel slab","slug":"kernel-slab","date":"2016-08-18T07:29:24.000Z","updated":"2018-12-31T11:18:45.000Z","comments":true,"path":"2016/08/18/kernel-slab/","link":"","permalink":"http://yoursite.com/2016/08/18/kernel-slab/","excerpt":"","text":"几个重要命令cat /proc/slabinfoslabtop FAST 10’ Making the Common Case the Only Case with Anticipatory Memory Allocation","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"http://yoursite.com/tags/内存管理/"},{"name":"slab","slug":"slab","permalink":"http://yoursite.com/tags/slab/"}]},{"title":"newOS","slug":"newOS","date":"2016-08-18T06:46:31.000Z","updated":"2018-12-31T11:18:12.000Z","comments":true,"path":"2016/08/18/newOS/","link":"","permalink":"http://yoursite.com/2016/08/18/newOS/","excerpt":"","text":"Cassandra quickstart on OSv with KVMhttps://github.com/cloudius-systems/osv/wiki/Cassandra-quickstart-on-OSv-with-KVMOSvOSv is a new open-source operating system for virtual-machines. OSv was designed from the ground up to execute a single application on top of a hypervisor, resulting in superior performance and effortless management when compared to traditional operating systems which were designed for a vast range of physical machines.OSv has new APIs for new applications, but also runs unmodified Linux applications (most of Linux’s ABI is supported) and in particular can run an unmodified JVM, and applications built on top of one. http://osv.io/downloads/","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"OSv","slug":"OSv","permalink":"http://yoursite.com/tags/OSv/"},{"name":"next generation OS","slug":"next-generation-OS","permalink":"http://yoursite.com/tags/next-generation-OS/"}]},{"title":"configs","slug":"configs","date":"2016-08-18T05:00:10.000Z","updated":"2018-12-31T11:17:30.000Z","comments":true,"path":"2016/08/18/configs/","link":"","permalink":"http://yoursite.com/2016/08/18/configs/","excerpt":"","text":"192.168.xxx.yyy —— xxx是peer id， yyy是vm id 192.168.25.30-40 25.3的ip192.168.25.40-50192.168.25.50-60192.168.25.60-70192.168.25.70-80192.168.25.80-90192.168.25.90-100192.168,25.100-110 virsh dumpxml VMNAME > backup.xml140 = 0x8c template.xml150 = 0x96 template_baseline.xml_ 160 = 0xa0 dev_baseline.xml_在低延迟和高速网络中，没必要开启sack(默认是1)echo 0 > /proc/sys/net/ipv4/tcp_sack 哲学，乃是某种介乎神学与科学之间的东西。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"网络配置","slug":"网络配置","permalink":"http://yoursite.com/tags/网络配置/"}]},{"title":"cloudsuite","slug":"cloudsuite","date":"2016-08-18T04:46:05.000Z","updated":"2018-12-31T11:16:52.000Z","comments":true,"path":"2016/08/18/cloudsuite/","link":"","permalink":"http://yoursite.com/2016/08/18/cloudsuite/","excerpt":"","text":"cloudsuite拷贝http://cloudsuite.ch/","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"benchmark","slug":"benchmark","permalink":"http://yoursite.com/tags/benchmark/"}]},{"title":"20160818","slug":"20160818 - 2","date":"2016-08-18T02:59:24.000Z","updated":"2018-12-31T11:16:34.000Z","comments":true,"path":"2016/08/18/20160818 - 2/","link":"","permalink":"http://yoursite.com/2016/08/18/20160818 - 2/","excerpt":"","text":"TODO 配置benchmark* 教训 简单规划，然后马上上手去做，不要总是想着该做什么，然后用很长时间去规划 http://brunogirin.blogspot.jp/2010/09/memory-usage-graphs-with-ps-and-gnuplot.html","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160818","slug":"20160818","date":"2016-08-18T02:59:04.000Z","updated":"2018-12-31T11:16:06.000Z","comments":true,"path":"2016/08/18/20160818/","link":"","permalink":"http://yoursite.com/2016/08/18/20160818/","excerpt":"","text":"什么都没写，不知道这一天干啥了…………………………","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"YCSB","slug":"YCSB","date":"2016-08-17T14:24:10.000Z","updated":"2018-12-31T11:15:37.000Z","comments":true,"path":"2016/08/17/YCSB/","link":"","permalink":"http://yoursite.com/2016/08/17/YCSB/","excerpt":"","text":"SOSP13Speedy Transactions in Multicore In-Memory DatabasesWe ran a variant of YCSB workload mix A; YCSB is Yahoo’s popular key- value benchmark.这篇文章运行YCSB工作负载的变种A主要做了三个改变： 固定读写比例80/20 把写操作改成了读-修改-写 把每条记录大小从1000B缩小到100B Our variant differs in the following ways: (a) we fix the read/write ratio to 80/20 (instead of 50/50), (b) we change write operations to read-modify- writes, which in MemSilo happen in a single transaction, and (c) we shrink the size of records to 100 bytes (in- stead of 1000 bytes). These modifications prevent unin- teresting overheads that affect both systems from hiding overheads that affect only MemSilo. More specifically, (a) prevents the memory allocator for new records from becoming the primary bottleneck, (b) creates a transac- tion that actually generates read-write conflicts, which stresses MemSilo’s protocol, and (c) prevents memcpy from becoming the primary bottleneck. Both transac- tions sample keys uniformly from the key space.We fix the tree size to contain 160M keys, and vary the number of workers performing transactions against the tree.TODO：下载https://github.com/brianfrankcooper/YCSB/releases 感觉redis状态有点奇怪，是不是其他机器上的redis没有跑起来？redis分析地址的方法？明天把stream跑起来，然后完整建立一个观察访问量的框架。。。YCSB和cloudsuite这两个哪个能够固定访问总量？Clearing the Clouds是EPFL发布的时候的文章这篇文章要引用！！！ bin/nodetool enablethriftbin/cassandra -f","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"benchmark","slug":"benchmark","permalink":"http://yoursite.com/tags/benchmark/"}]},{"title":"misc20160817","slug":"20160817","date":"2016-08-17T08:36:22.000Z","updated":"2018-12-31T11:15:06.000Z","comments":true,"path":"2016/08/17/20160817/","link":"","permalink":"http://yoursite.com/2016/08/17/20160817/","excerpt":"现在所有机器的ip地址","text":"现在所有机器的ip地址192.168.xxx.yyy —— xxx是peer id， yyy是vm id 192.168.25.30-40 25.3的ip192.168.25.40-50192.168.25.50-60192.168.25.60-70192.168.25.70-80192.168.25.80-90192.168.25.90-100192.168,25.100-110 目前选择benchmark是kubernetes上面提到一个pod里面的多个benchmark。 Jiri“Jiri integrates repositories intelligently”Jiri is a tool for multi-repo development. It supports:• syncing multiple local repos with upstream,• capturing the current state of all local repos in a “snapshot”,• restoring local project state from a snapshot, and• facilitating sending change lists to Gerrit.Jiri has an extensible plugin model, making it easy to create new sub-commands.Jiri is open-source. See the contributor guidelines here. Magenta is the core platform that powers the Fuchsia OS. Magenta is composed of a microkernel (source in kernel/…) as well as a small set of userspace services, drivers, and libraries (source in system/…) necessary for the system to boot, talk to hardware, load userspace processes and run them, etc. Fuchsia builds a much larger OS on top of this foundationhttps://github.com/fuchsia-mirror/magenta","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"route add","slug":"route-add","date":"2016-08-16T11:03:55.000Z","updated":"2018-12-31T11:14:50.000Z","comments":true,"path":"2016/08/16/route-add/","link":"","permalink":"http://yoursite.com/2016/08/16/route-add/","excerpt":"","text":"在插入无线网卡之后，需要添加一条默认路由","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"网络配置","slug":"网络配置","permalink":"http://yoursite.com/tags/网络配置/"}]},{"title":"misc20160816","slug":"20160816","date":"2016-08-16T02:37:16.000Z","updated":"2018-12-31T11:14:14.000Z","comments":true,"path":"2016/08/16/20160816/","link":"","permalink":"http://yoursite.com/2016/08/16/20160816/","excerpt":"sudo gem install i2cssh vim /.i2csshrc vim /.i2csshrc i2cssh tnvmservers","text":"sudo gem install i2cssh vim /.i2csshrc vim /.i2csshrc i2cssh tnvmservers TODOiperf的使用 同步server到mac，同步server到clients在哪台机器上，就写在这台机器上执行的脚本，最后再同步专注在10上的开发 route -nroute add -net 10.0.0.0/16 gw 10.107.0.1route del default find /var/cache/apt/archives/ -type f -ctime -50 -exec cp {} /root/tmp \\; sudo dpkg -i –force-overwrite /var/cache/apt/archives/libjline-java.deb","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"eurosys16","slug":"eurosys16","date":"2016-08-15T12:54:47.000Z","updated":"2018-12-31T11:13:42.000Z","comments":true,"path":"2016/08/15/eurosys16/","link":"","permalink":"http://yoursite.com/2016/08/15/eurosys16/","excerpt":"","text":"Data Tiering in Heterogeneous Memory Systems分析了三种数据中心应用*including a key-value store (MemC3), an in- memory database (VoltDB), anda graph analytics frame- work (GraphMat) – 文章体系结构假设同样是少量DRAM和大量NVM Log-structured Memory for DRAM-based StorageLeveraging Heterogeneity in DRAM Main Memories to Accelerate Critical Word Access这篇文章的借鉴价值在于它的实验部分，它也利用了多种混合内存的策略，在它的实验一中，展示了不同内存比例在CW优化下的性能，同样我们可以采用，不同混合内存比例在SWAP优化下的性能比例。","categories":[{"name":"科研","slug":"科研","permalink":"http://yoursite.com/categories/科研/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"http://yoursite.com/tags/内存管理/"},{"name":"hybrid-mem","slug":"hybrid-mem","permalink":"http://yoursite.com/tags/hybrid-mem/"}]},{"title":"20160814","slug":"20160814","date":"2016-08-14T11:29:49.000Z","updated":"2018-12-31T11:12:39.000Z","comments":true,"path":"2016/08/14/20160814/","link":"","permalink":"http://yoursite.com/2016/08/14/20160814/","excerpt":"今天做了什么跟老板申请使用服务器集群，老板马上就同意了，我要好好干啦！效率比较低下。","text":"今天做了什么跟老板申请使用服务器集群，老板马上就同意了，我要好好干啦！效率比较低下。 有什么需要纠正的每天要去看看自己做过的实验，并且看一下实验的数据，进行总结。这些大概只要5min 再有就是锻炼自己去及一些东西 有什么应该做没有做的没有朗读eng 有什么收获发现很多事情都要靠自己，不要盲目觉得别人可以帮助你，这都是不现实的。 什么糟糕的事情恩恩，没什么吧。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160810","slug":"20160810","date":"2016-08-10T16:33:47.000Z","updated":"2018-12-31T11:12:31.000Z","comments":true,"path":"2016/08/11/20160810/","link":"","permalink":"http://yoursite.com/2016/08/11/20160810/","excerpt":"今天做了什么今天实现了比特映射机制，观察的到的访存分布不均匀需要进一步的理解，以及发掘怎么利用。读重构那本书得到了一些重构的基本原则，下午去打了个球，感觉还好。恩就这样过了一天","text":"今天做了什么今天实现了比特映射机制，观察的到的访存分布不均匀需要进一步的理解，以及发掘怎么利用。读重构那本书得到了一些重构的基本原则，下午去打了个球，感觉还好。恩就这样过了一天 有什么需要纠正的每天要去看看自己做过的实验，并且看一下实验的数据，进行总结。这些大概只要5min 再有就是锻炼自己去及一些东西 有什么应该做没有做的没有朗读eng 有什么收获发现很多事情都要靠自己，不要盲目觉得别人可以帮助你，这都是不现实的。 什么糟糕的事情恩恩，没什么吧。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160811","slug":"20160811","date":"2016-08-10T16:33:36.000Z","updated":"2018-12-31T11:12:25.000Z","comments":true,"path":"2016/08/11/20160811/","link":"","permalink":"http://yoursite.com/2016/08/11/20160811/","excerpt":"今天做了什么今天和同学聊天，有些感触。这里就不说了。。。 文章找到了新的模板，但是插入图片的有问题。","text":"今天做了什么今天和同学聊天，有些感触。这里就不说了。。。 文章找到了新的模板，但是插入图片的有问题。 有什么需要纠正的今天本来想要做实验证明重新映射的关系，但是没有做，时间紧迫啊！！！ 有什么应该做没有做的没有朗读eng 有什么收获坚持，get better! 什么糟糕的事情恩恩，没什么吧。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"重构，改善既有代码的设计 \\<16\\~33\\>","slug":"重构，改善既有代码的设计-16-33","date":"2016-08-10T08:29:19.000Z","updated":"2018-12-31T10:57:59.000Z","comments":true,"path":"2016/08/10/重构，改善既有代码的设计-16-33/","link":"","permalink":"http://yoursite.com/2016/08/10/重构，改善既有代码的设计-16-33/","excerpt":"今天继续看的部分，还是继续对statement()函数的分解和重组，使用了三个技术 Move Method Replace Temp with Query Extract Method","text":"今天继续看的部分，还是继续对statement()函数的分解和重组，使用了三个技术 Move Method Replace Temp with Query Extract Method Move Method发现重构机会首先第一个Move Method的初衷就是发现函数没有放在它所使用的数据的所属对象里面，这里就不具体说了 重构方法一般来说方法应当把代码放在它所使用的数据所属对象里面，调整代码并且立即重新编译 Replace Temp with Query发现重构机会临时变量会助长冗长的函数，尽量消除临时变量 重构方法为临时变量创建查询函数，用查询函数代替临时变量 Extract Method发现重构机会发现有部分代码可以提取成函数，并且有利于下一步的修改，例如这里statement函数里面对积分的操作，为了便于积分规则的修改，可以将这部分代码提取成函数 重构方法将完成某一个特定功能的代码提取成一个函数，即便这个功能是在循环中完成，需要在新函数中重新遍历。 总结今天这三个重构的方法感觉都很具体，也很实用，改变函数的位置，用查询替换临时变量，以及把完成特定功能的代码单独出来成为函数，都是非常正确的，最后一种重构方法虽然会带来额外的开销，但是它提供的更好的软件架构是更重要的，在书中p69说了这么一句话： 虽然重构可能使软件运行更慢，但它也是软件的性能优化更容易编写快速软件的秘密就是：首先写出可调的软件，然后调整它以求获得足够速度。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"读书","slug":"读书","permalink":"http://yoursite.com/tags/读书/"},{"name":"refactoring","slug":"refactoring","permalink":"http://yoursite.com/tags/refactoring/"},{"name":"代码架构设计","slug":"代码架构设计","permalink":"http://yoursite.com/tags/代码架构设计/"}]},{"title":"重构，改善既有代码的设计","slug":"重构，改善既有代码的设计","date":"2016-08-09T10:56:38.000Z","updated":"2018-12-31T10:57:52.000Z","comments":true,"path":"2016/08/09/重构，改善既有代码的设计/","link":"","permalink":"http://yoursite.com/2016/08/09/重构，改善既有代码的设计/","excerpt":"今天买了一本新书，Refactoring improvint the design of existing code这是一本关于重构的书籍，作者是martin flowler 当然，这里的重构是针对面向对象程序的，关于面向程序架构的设计，有很多值得学习的东西，这本书解释了重构的原理和最佳实践。提供了一系列完整的重构方法。","text":"今天买了一本新书，Refactoring improvint the design of existing code这是一本关于重构的书籍，作者是martin flowler 当然，这里的重构是针对面向对象程序的，关于面向程序架构的设计，有很多值得学习的东西，这本书解释了重构的原理和最佳实践。提供了一系列完整的重构方法。 什么是重构重构本身是在不改变代码外在行为的前提下，对代码做出修改，以改进程序的内部结构。 重构的每个步骤都很简单，通常是把一个字段从一个类移到另一个类，把某些代码从一个函数拉出来构成另一个函数，或者在继承体系中把某些代码推上推下就行了。 这本书分为四大部分 第一章展示了一个小程序，并且对它的设计缺陷进行修改 第二章讨论了重构的一般原则，定义，以及进行重构的原因 第三章，大神Kent Beck讲述如何嗅出代码中的坏味道，并且使用重构清除这些 第四章，介绍了如何使用简单的开源java测试框架，在代码中构筑测试环境。 后面就是所有的重构方法的集合。。。。 接下来，看了第一章的前几部分，其实要分辨差劲的代码很简单，哪些很难修改的代码就是差劲的代码，在这些代码中通常很难找到修改点，这种很难找到修改点的程序，通常会很容易引入bug。 第二个让我觉得值得注意的就是，当决定要重构的时候，需要为即将修改的代码建立一组可靠的测试环境。 比如书中给出的第一个例子，那块很大的statement()函数，很想让人把它大写八块，把其中的一部分代码提炼出来，形成单独的函数，并且进行一定的变量重命名操作。 OK， 今天的半小时阅读就到这里。 决定开始重构我的hybrid mem代码啦。。。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"读书","slug":"读书","permalink":"http://yoursite.com/tags/读书/"},{"name":"refactoring","slug":"refactoring","permalink":"http://yoursite.com/tags/refactoring/"},{"name":"代码架构设计","slug":"代码架构设计","permalink":"http://yoursite.com/tags/代码架构设计/"}]},{"title":"kubernetes是什么","slug":"kubernetes是什么","date":"2016-08-09T06:13:20.000Z","updated":"2018-12-31T11:12:07.000Z","comments":true,"path":"2016/08/09/kubernetes是什么/","link":"","permalink":"http://yoursite.com/2016/08/09/kubernetes是什么/","excerpt":"","text":"kubernetes是什么，在经过一个小时的探索之后，我其实也并没有看懂，暂且对我目前的认知做一个总结。 kubernetes是一个以pod为单位调度的框架。k里面比较重要的理念就是decouple，将前端和后端去耦合，在开发者角度来说看到的是同质化的机器抽象，并不用关心后端实际物理机器的生死。 涉及到几个关键概念，pod， controller. 以后慢慢在实践中摸索吧，我不只想做一个devops。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"k8s","slug":"k8s","permalink":"http://yoursite.com/tags/k8s/"}]},{"title":"Transparent management in IaaS cloud","slug":"Transparent-management-in-IaaS-cloud","date":"2016-08-08T02:49:48.000Z","updated":"2018-12-31T11:11:33.000Z","comments":true,"path":"2016/08/08/Transparent-management-in-IaaS-cloud/","link":"","permalink":"http://yoursite.com/2016/08/08/Transparent-management-in-IaaS-cloud/","excerpt":"这篇博文论证一个问题，为什么在IaaS云中，提供透明的内存管理是必要的. ESX by VMware In ESX, the memory management techniques allow the virtual machines to use more memory thanthe physical machines available memory.-For example, you can have a host with 2GB memory and run four virtual machines with 1GBmemory each. In that case, the memory is overcommitted. To improve memory utilization, ESX transfersmemory from idle virtual machine to virtual machines that need more memory .-Transparent Page Sharing (TPS) When multiple VMs are running, some of them may have identical sets of memory content(several VMs may be running the same OS, applications and the same user data). With page sharing thehypervisor can reclaim the redundant copies and only keep one copy, which is shared by multiple virtualmachines in the host physical memory. Example 4shared, Github. Ballooning A driver used to communicate with applications to understand their memory needs to make roomfor other applications.","text":"这篇博文论证一个问题，为什么在IaaS云中，提供透明的内存管理是必要的. ESX by VMware In ESX, the memory management techniques allow the virtual machines to use more memory thanthe physical machines available memory.-For example, you can have a host with 2GB memory and run four virtual machines with 1GBmemory each. In that case, the memory is overcommitted. To improve memory utilization, ESX transfersmemory from idle virtual machine to virtual machines that need more memory .-Transparent Page Sharing (TPS) When multiple VMs are running, some of them may have identical sets of memory content(several VMs may be running the same OS, applications and the same user data). With page sharing thehypervisor can reclaim the redundant copies and only keep one copy, which is shared by multiple virtualmachines in the host physical memory. Example 4shared, Github. Ballooning A driver used to communicate with applications to understand their memory needs to make roomfor other applications. 在ESX中，内存管理允许虚拟机使用比实际物理机器可用内存更多的内存。这样机会对客户机器定义了一种透明性，客户机器不用关心底层对内存管理的细节。内存的材质，内存的大小，对于云计算的租户来说，只需要提供他的任务需求。 透明页共享，由宿主机器来管理虚拟机之间共享的内存页。 透明大页 Transparent Hardware Management of Stacked DRAM as Part of Memory. In contrast to OS-managed policies,our approach is transparent to software and achieves higherperformance due to its ability to adapt and remap data at afine granularity Incontrast, our system must provide the ability to remap physicaladdresses in order to support the transparent swappingof memory blocks between fast and slow memory. This paper presents a Part-ofMemory(PoM) architecture that effectively combines slowand fast memory to create a single physical address spacein an OS-transparent fashion. Huge pages can be difficult to manage manually, and often require significant changes to code in order to be used effectively. As such, Red Hat Enterprise Linux 6 also implemented the use of transparent huge pages (THP). THP is an abstraction layer that automates most aspects of creating, managing, and using huge pages.THP hides much of the complexity in using huge pages from system administrators and developers. As the goal of THP is improving performance, its developers (both from the community and Red Hat) have tested and optimized THP across a wide range of systems, configurations, applications, and workloads. This allows the default settings of THP to improve the performance of most system configurations. However, THP is not recommended for database workloads. 大页的人工设置比较困难，如果要高效利用通常需要对代码进行很大的改进。因此红帽子采用了透明大页，透明大页是一个抽象层，它自动进行大页的创建，管理以及使用。THP对系统管理人员和开发者隐藏了使用大页的大部分复杂性。并且它的开发者进行了广泛的测试，是的THP的默认配置，能够优化大部分的系统性能。 [ACSIC Speaker Series #6] 前车之鉴 by Prof. Yuanyuan Zhou from UCSD","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"},{"name":"内存管理","slug":"内存管理","permalink":"http://yoursite.com/tags/内存管理/"}]},{"title":"20160805","slug":"20160805","date":"2016-08-05T17:35:21.000Z","updated":"2018-12-31T11:10:58.000Z","comments":true,"path":"2016/08/06/20160805/","link":"","permalink":"http://yoursite.com/2016/08/06/20160805/","excerpt":"今天做了什么买了几本书，然后就开始工作了。今天其实很倒霉，差点把代码库都毁了，然后又把发票撕烂了。打球还戳到了手指。Bad day~ 今天通过跟redhat 的zhang Fam 进行讨论，我发现很可能瓶颈并不在coroutine。而且即便实现了coroutine，并不能够很大程度帮助论文的创新。","text":"今天做了什么买了几本书，然后就开始工作了。今天其实很倒霉，差点把代码库都毁了，然后又把发票撕烂了。打球还戳到了手指。Bad day~ 今天通过跟redhat 的zhang Fam 进行讨论，我发现很可能瓶颈并不在coroutine。而且即便实现了coroutine，并不能够很大程度帮助论文的创新。 计划执行情况如下： 每天拉屎…… 坐姿要注意啦，劲椎痛 单杠 蹲墙功 每天记一点东西 眼操 颈椎活动 每天出门吃一次饭 有什么需要纠正的觉得有时候做事情毛躁。早上起来和中午起来工作之前还是要运动一下比较合适。 有什么应该做没有做的没有朗读eng 有什么收获买了书算吗？ 什么糟糕的事情恩恩，没什么吧。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"redis端分析","slug":"redis端分析","date":"2016-08-05T16:20:34.000Z","updated":"2018-12-31T11:10:46.000Z","comments":true,"path":"2016/08/06/redis端分析/","link":"","permalink":"http://yoursite.com/2016/08/06/redis端分析/","excerpt":"","text":"1234567891011121314151617181920212223void swapInit(void) &#123;...... sleep(5); server.remote_swaps = dictCreate(&amp;keyptrDictType, NULL); di = dictGetSafeIterator(server.hybridswap_peers); while(NULL != (de = dictNext(di))) &#123; p = dictGetEntryVal(de); r = swapConnectToPeer(p); if (r) &#123; redisAeAttach(server.el, p-&gt;write_ctx); redisAeAttach(server.el, p-&gt;read_ctx); redisAeAttach(server.el, p-&gt;ping_ctx); redisAsyncSetConnectCallback(p-&gt;ping_ctx, swapConnectCallback); redisAsyncSetDisconnectCallback(p-&gt;ping_ctx, swapDisconnectCallback); &#125; //aeCreateTimeEvent(server.el, 1, swappingRemote, (void*)p, NULL); &#125; dictReleaseIterator(di);&#125; 在redis端的主要任务就是创建两种dict,一种是用来存储有多少个peer的字典，名字叫做hybridswap_peers，另外一个是用来存储数据的，这个名字叫做remote_swaps 然后创建了三个redisAsyncContext也就是异步上下文，分别是读写和ping的上下文。并且制定了ping上下文的连接与断开的回调函数。 对于remote_swaps来说，这个是我们需要关注的主要dict. hiredis/examples/example-ae.c","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"Isaac Asimov的科幻故事","slug":"Isaac-Asimov的科幻故事","date":"2016-08-05T01:47:02.000Z","updated":"2018-12-31T11:10:26.000Z","comments":true,"path":"2016/08/05/Isaac-Asimov的科幻故事/","link":"","permalink":"http://yoursite.com/2016/08/05/Isaac-Asimov的科幻故事/","excerpt":"今天早上冲动消费，接连买了四本电子书。 永恒的终结 神们自己 无人生还 蝴蝶梦前两本是阿西莫夫的，后面一个是阿加莎的侦探小说，一个是爱情小说（蛤蛤）","text":"今天早上冲动消费，接连买了四本电子书。 永恒的终结 神们自己 无人生还 蝴蝶梦前两本是阿西莫夫的，后面一个是阿加莎的侦探小说，一个是爱情小说（蛤蛤） 《永恒的终结》24世纪，人类发明了时间力场。27世纪，人类在掌握时间旅行技术后，成立了一个叫做永恒时空（Eternity）的组织，在每个时代的背后，默默地守护着人类社会的发展。永恒时空以一个世纪为单位，并视每个世纪的发展需要而加以微调，以避免社会全体受到更大伤害。通过纠正过去的错误，将所有灾难扼杀在萌芽中，人类终于获得安宁的未来。然而，这种“绝对安全”的未来却在某一天迎来了终结。不知不觉中形成的因果链，仿佛从四面八方涌来的黑暗，即将吞噬全人类。安德鲁•哈伦，生于95世纪，他是永恒时空的时空技师、人类未来社会的精英。他的天职是靠操纵时空壶，进行时间旅行来守护500亿人类，而在一次时空任务中，他邂逅了令他一见倾心的姑娘，而突然来到的爱情却让他开始质疑整个世界。同时，人类最后的希望，也落在了时间旅行者安德鲁•哈伦最后的时空任务上…… 《神们自己》22世纪，地球可以和平行宇宙进行物质交换，从此拥有了源源不绝的能源。但是，只有几个人才知道危险的真相：地球上的一个无人信任的科学家、能源渐渐枯竭的星球上的一个外星人、月球上出生的一个拥有预言能力的人类。只有他们知道，人类即将为看似源源不绝的免费能源付出巨大的代价……太 阳即将毁灭，可是无人倾听。真相，永远掌握在极少数人的手里。面对愚昧，神们自己也缄口不言……","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"},{"name":"科幻","slug":"科幻","permalink":"http://yoursite.com/tags/科幻/"}]},{"title":"20160804","slug":"20160804","date":"2016-08-04T16:17:01.000Z","updated":"2018-12-31T11:10:00.000Z","comments":true,"path":"2016/08/05/20160804/","link":"","permalink":"http://yoursite.com/2016/08/05/20160804/","excerpt":"今天做了什么今天继续进行改代码，同样还是在看一本关于以色列的传记，对于和平的争论在以色列国内从未停息，他们认为，既然以色列国内存在着对于建立定居点等等犹太复国主义行动的争论，那么以色列这个国家行为就是正确的，因为它也曾经考虑到了巴勒斯坦人的存在。作者采访了多位以色列的左派人士，他也承认了左派虽然提出了关于和平的构想，但是没有拿出卓有成效的行动。吕大城的故事没有人会忘记，六日战争已经让锡安主义得到了一定的支撑，无论如何，以色列还将以现在这样强势地存在着，虽然很多人从正义的角度看到了一些隐忧，然而并不能否认的是，这个国家已经取得了瞩目的成就。","text":"今天做了什么今天继续进行改代码，同样还是在看一本关于以色列的传记，对于和平的争论在以色列国内从未停息，他们认为，既然以色列国内存在着对于建立定居点等等犹太复国主义行动的争论，那么以色列这个国家行为就是正确的，因为它也曾经考虑到了巴勒斯坦人的存在。作者采访了多位以色列的左派人士，他也承认了左派虽然提出了关于和平的构想，但是没有拿出卓有成效的行动。吕大城的故事没有人会忘记，六日战争已经让锡安主义得到了一定的支撑，无论如何，以色列还将以现在这样强势地存在着，虽然很多人从正义的角度看到了一些隐忧，然而并不能否认的是，这个国家已经取得了瞩目的成就。 代码这边，基本上已经完成了框架的搭建，明天需要把写的那一半完成，就要赶快拿到机器上进行调试了。 今天做了一些新的计划，希望以后能够达成。 每天拉屎…… 坐姿要注意啦，劲椎痛 单杠 蹲墙功 每天记一点东西 眼操 颈椎活动 每天出门吃一次饭 有什么需要纠正的有时候会发呆 有什么应该做没有做的没有朗读eng 有什么收获保持自己在愉快的状态下学习能够有更好的效率和记忆力 什么糟糕的事情恩恩，没什么吧。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"20160802","slug":"20160802","date":"2016-08-02T17:19:56.000Z","updated":"2018-12-31T11:09:54.000Z","comments":true,"path":"2016/08/03/20160802/","link":"","permalink":"http://yoursite.com/2016/08/03/20160802/","excerpt":"今天做了什么今天又是看代码，改代码的一天，这是第三天了，终于有了一些端倪，基本上整理出了思路。明天改完测试一下吧。看了一本讲以色列的书，锡安主义的恐怖之处在于，他们其实也有正当的诉求，并且他们本身也是被压迫的民族，这就是弱肉强食，弱肉再食更弱的肉。。。看到了以色列人对阿拉伯的强硬，在第三帝国面前的软弱，感慨这个夹缝中的民族的不易，一切正义在这时候看起来都是片面的。","text":"今天做了什么今天又是看代码，改代码的一天，这是第三天了，终于有了一些端倪，基本上整理出了思路。明天改完测试一下吧。看了一本讲以色列的书，锡安主义的恐怖之处在于，他们其实也有正当的诉求，并且他们本身也是被压迫的民族，这就是弱肉强食，弱肉再食更弱的肉。。。看到了以色列人对阿拉伯的强硬，在第三帝国面前的软弱，感慨这个夹缝中的民族的不易，一切正义在这时候看起来都是片面的。 有什么需要纠正的还是效率问题，喝了咖啡还是好一些。 有什么应该做没有做的没有背单词 有什么收获今天终于可以说看懂了基本的执行机制了，下一步要赶快动手了。 什么糟糕的事情恩恩，没什么吧。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"rethinking swap","slug":"rethinking-swap","date":"2016-08-02T07:46:44.000Z","updated":"2018-12-31T11:09:40.000Z","comments":true,"path":"2016/08/02/rethinking-swap/","link":"","permalink":"http://yoursite.com/2016/08/02/rethinking-swap/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940//swap\\_file\\_open设置,调用swap\\_aio\\_event\\_readerqemu\\_aio\\_set\\_fd\\_handler(s-\\&gt;fds[SWAP\\_FD\\_READ], swap\\_aio\\_event\\_reader, NULL, swap_aio_flush_cb, NULL, s);swap\\_aio\\_event\\_reader--\\&gt;swap\\_complete\\_aio--\\&gt;swap\\_aio\\_bh\\_cb//acb-\\&gt;bh = qemu\\_bh\\_new(swap\\_aio\\_bh\\_cb, acb);/\\* Callback when all queued swap\\_aio requests are complete \\*/static void swap\\_aio\\_bh\\_cb(void \\*opaque)&#123; SWAPAIOCB *acb = opaque; if (!acb-&gt;write) &#123; qemu_iovec_from_buffer(acb-&gt;qiov, acb-&gt;buf, acb-&gt;qiov-&gt;size);//读取数据 &#125; qemu_vfree(acb-&gt;buf); acb-&gt;common.cb(acb-&gt;common.opaque, (acb-&gt;ret &gt; 0 ? 0 : acb-&gt;ret)); qemu_bh_delete(acb-&gt;bh); acb-&gt;bh = NULL; //fprintf(stderr, \"%d %d %lx %d\\n\", acb-&gt;write, acb-&gt;size, acb-&gt;sector_num, acb-&gt;ret); qemu_aio_release(acb);&#125;//另外一个回调函数是在每个job都会回调的，在swap\\_aio\\_rw\\_vector里面设置job-\\&gt;cb = swap\\_finish\\_aiocb;//swap\\_finish\\_aiocb这个cb在worker function里面执行，主要目的就是处理一些元数据，比如remain\\_pages这样的。然后处理完了之后就通过管道告知。//当管道通知之后就会调用上面注册的swap\\_aio\\_bh\\_cb读取数据啦。//对比sheepdog//首先相同点，都是在read函数开始的时候创建acb，这个acb完成执行这次读的所有请求。每个读请求都是对应一个acb的。然而在swap的job中制定了回调函数。//在sheepdog中，同样是每个请求都指定了acb, 总结在swap中，open的时候注册fd handler用于接收read response得到的数据。在队列的workder function执行完的时候调用job对应的callback，这个callback在读完成或者写完成的时候回写fd，通知前面注册的fd handler完成读取数据的工作。总的来看，open中初始化队列已经为所有的worker连接到了redis.也就是说在open中已经建立了基本的框架，读写的函数只要想队列里面加入读写请求就行了。 在sheepdog中，open的时候初始化了几个关键的队列，包括请求队列，callback队列和协程队列。在sheepdog的sd_co_readv中，新建ACB, 然后在sd_co_rw_vector中，为每个len长的数据新建aio_req，然后将请求插入队列，并且在add_aio_request注册了fd handler处理返回的数据，不过sheep首先要阻塞socket,先发送一个header，然后再在fd handler中处理header数据，并且接收返回的数据。 改造过程中，我需要在add_aio_request中首先建立连接？然后处理请求，然后执行请求的callback,在请求的call back中写入fd, 然后在fd handler中接收数据。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"}]},{"title":"20160801","slug":"20160801","date":"2016-08-01T17:15:47.000Z","updated":"2018-12-31T11:08:46.000Z","comments":true,"path":"2016/08/02/20160801/","link":"","permalink":"http://yoursite.com/2016/08/02/20160801/","excerpt":"今天做了什么过去的事情难以记起，难辨真假了。 学习效率不太高，本来说好今天完成的工作没有完成。 有什么需要纠正的其实觉得自己并没有怎么浪费时间，但是时间就是这样过去了。 有什么应该做没有做的今天很多事情都没干啊","text":"今天做了什么过去的事情难以记起，难辨真假了。 学习效率不太高，本来说好今天完成的工作没有完成。 有什么需要纠正的其实觉得自己并没有怎么浪费时间，但是时间就是这样过去了。 有什么应该做没有做的今天很多事情都没干啊 有什么收获跟大家吃了饭，长胖了哈哈 什么糟糕的事情有的事情，和目标无关的事情就是要马上去做，发生了的事情，不要苦恼，做完了无关的事情，才能专注去做该做的事情。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"sheepdog源码阅读","slug":"sheepdog源码阅读","date":"2016-07-31T05:46:07.000Z","updated":"2018-12-31T11:09:35.000Z","comments":true,"path":"2016/07/31/sheepdog源码阅读/","link":"","permalink":"http://yoursite.com/2016/07/31/sheepdog源码阅读/","excerpt":"这篇博文主要关注sheepdog中的打开存储系统的初始化设置以及基本的读写操作，并不关注sheepdog中有关分布式的内容。在sheepdog中，读写请求的处理是通过将对应的请求以及相应的 sd_opensd_open主要完成了初始化的工作，包括初始化了三个重要的链表。","text":"这篇博文主要关注sheepdog中的打开存储系统的初始化设置以及基本的读写操作，并不关注sheepdog中有关分布式的内容。在sheepdog中，读写请求的处理是通过将对应的请求以及相应的 sd_opensd_open主要完成了初始化的工作，包括初始化了三个重要的链表。 12345678910111213141516static int sd\\_open(BlockDriverState *bs, QDict *options, int flags, Error **errp)&#123; //.............. QLIST_INIT(&amp;s-&gt;inflight_aio_head); QLIST_INIT(&amp;s-&gt;failed_aio_head); QLIST_INIT(&amp;s-&gt;inflight_aiocb_head); //然后连接到sheeodog，读取inode元数据 fd = connect_to_sdog(s, errp); ret = read_object(fd, s-&gt;aio_context, buf, vid_to_vdi_oid(vid), 0, SD_INODE_SIZE, 0, s-&gt;cache_flags); //最后初始化协程队列和协程锁 qemu_co_mutex_init(&amp;s-&gt;lock); qemu_co_queue_init(&amp;s-&gt;overlapping_queue);&#125; sd_co_readvsd_co_readv协程处理读请求12345678910111213141516171819202122232425262728static coroutine\\_fn int sd\\_co\\_readv(BlockDriverState \\*bs, int64\\_t sector\\_num, int nb_sectors, QEMUIOVector *qiov)&#123; //为这个请求申请分配acb，进行一系列设置（包括在acb保存当前的协程） acb = sd_aio_setup(bs, qiov, sector_num, nb_sectors); //然后查找当前的请求是不是已经在inflight_aiocb_head里面了，如果重复了，就把当前的协程加入到协程队列的队尾,然后重试 retry: if (check_overlapping_aiocb(s, acb)) &#123; qemu_co_queue_wait(&amp;s-&gt;overlapping_queue); goto retry; &#125; //以len为长度，构造请求加入到inflight_aio_head队列，不等请求响应就返回，返回的请求由aio_read_response处理。 //由sd_co_rw_vector里面的add_aio_request函数创建协程，调用aio_read_response处理请求的返回信息。 ret = sd_co_rw_vector(acb); if (ret &lt;= 0) &#123; QLIST_REMOVE(acb, aiocb_siblings); qemu_co_queue_restart_all(&amp;s-&gt;overlapping_queue); qemu_aio_unref(acb); return ret; &#125; //问题是yield之后restart all是什么意思呢？我理解这里是唤醒调度 qemu_coroutine_yield(); //yield之后，把控制权交回调用了qemu_coroutine_enter的位置，现在需要把acb从队列中移除，然后重启其它所有协程 QLIST_REMOVE(acb, aiocb_siblings); qemu_co_queue_restart_all(&amp;s-&gt;overlapping_queue); return acb-&gt;ret;&#125; 函数调用关系：sd_co_rw_vector–> add_aio_request –>aio_set_fd_handler(s->aio_context, s->fd, false, co_read_response, co_write_request, s); –&gt; co_read_response &amp;&amp; co_write_request co_read_response[非协程，是fd handler] 创建协程--&gt;aio_read_response add_aio_request123456789101112131415161718192021222324252627282930313233343536373839404142434445static void coroutine\\_fn add\\_aio\\_request(BDRVSheepdogState *s, AIOReq *aio\\_req, struct iovec *iov, int niov, enum AIOCBState aiocb_type)&#123; //..... aio_set_fd_handler(s-&gt;aio_context, s-&gt;fd, false, co_read_response, co_write_request, s); //.....&#125;static void co\\_read\\_response(void \\*opaque)&#123; BDRVSheepdogState *s = opaque; if (!s-&gt;co_recv) &#123; s-&gt;co_recv = qemu_coroutine_create(aio_read_response, opaque); &#125; qemu_coroutine_enter(s-&gt;co_recv);&#125;//最终落到需要aio\\_read\\_response来接收数据，static void coroutine\\_fn aio\\_read\\_response(void \\*opaque)&#123; SheepdogObjRsp rsp; BDRVSheepdogState *s = opaque; //... case AIOCB_READ_UDATA: ret = qemu_co_recvv(fd, acb-&gt;qiov-&gt;iov, acb-&gt;qiov-&gt;niov, aio_req-&gt;iov_offset, rsp.data_length); //... free_aio_req(s, aio_req); if (!acb-&gt;nr_pending) &#123; /* * We've finished all requests which belong to the AIOCB, so * we can switch back to sd_co_readv/writev now. */ acb-&gt;aio_done_func(acb); &#125; //...&#125;//如果执行到上面括号里面，最终请求控制权就又回到了sd\\_co\\_readv，最后执行下面两句话， QLIST_REMOVE(acb, aiocb_siblings); qemu_co_queue_restart_all(&amp;s-&gt;overlapping_queue); 总结通过这次的阅读，可以发现，sheepdog的基本机制是就是把传统的callback的机制改成了使用coroutine的方法，在读写的时候，每个读协程把请求加入队列就可以yield，然后由注册了的fd handler创建协程接收读取的数据，最终完成读写。 从不同的实现机制来理解，这个机制跟同步执行相比，就是把一个请求–等待数据返回–完成请求的过程分成了，把请求加入队列并返回–等待数据返回并且完成–唤醒原协程的过程。从逻辑上来看，这和多线程工作队列的执行过程和逻辑是相同的。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"}]},{"title":"20160731","slug":"20160731","date":"2016-07-30T17:48:13.000Z","updated":"2018-12-31T11:07:33.000Z","comments":true,"path":"2016/07/31/20160731/","link":"","permalink":"http://yoursite.com/2016/07/31/20160731/","excerpt":"今天做了什么coroutine基本了解了，参考了null和sheepdog，明天必须实现完成！半夜，去跑步释放了郁闷。。。 有什么需要纠正的今天没有读文章啊。。。感觉效率不高 有什么应该做没有做的quora没看","text":"今天做了什么coroutine基本了解了，参考了null和sheepdog，明天必须实现完成！半夜，去跑步释放了郁闷。。。 有什么需要纠正的今天没有读文章啊。。。感觉效率不高 有什么应该做没有做的quora没看 有什么收获了解了qemu的coroutine运行基本机制。 什么糟糕的事情突然觉得离deadline好近，然后自己又还没有搞定，着急啊。 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"偶遇一个大牛blogger","slug":"偶遇一个大牛blogger","date":"2016-07-30T04:41:14.000Z","updated":"2018-12-31T05:38:26.000Z","comments":true,"path":"2016/07/30/偶遇一个大牛blogger/","link":"","permalink":"http://yoursite.com/2016/07/30/偶遇一个大牛blogger/","excerpt":"今天看coroutine的c库，偶遇大牛云风，看了一下，skynet还是很厉害，能和Go过过招。贴一下链接吧。","text":"今天看coroutine的c库，偶遇大牛云风，看了一下，skynet还是很厉害，能和Go过过招。贴一下链接吧。 云风的博客 下面这个人，好像是QEMU的作者啊，文风大气，逻辑清楚。 Stefan Hajnoczi 诡辩之苏格拉底辩论法，要不要试一试？？？ 每个人的心里都有真善美，同时每个人都有喜怒。 Plus ca change.plus c’est la meme chose","categories":[],"tags":[]},{"title":"The QEMU coroutine API","slug":"The-QEMU-coroutine-API","date":"2016-07-29T17:50:46.000Z","updated":"2018-12-31T11:07:21.000Z","comments":true,"path":"2016/07/30/The-QEMU-coroutine-API/","link":"","permalink":"http://yoursite.com/2016/07/30/The-QEMU-coroutine-API/","excerpt":"QEMU的协程接口，这里介绍了几个主要函数，没有翻译，自己看看。 The QEMU coroutine APIThe coroutine API is documented in include/block/coroutine.h. The main functions are: 12typedef void coroutine\\_fn CoroutineEntry(void \\*opaque);Coroutine *qemu\\_coroutine\\_create(CoroutineEntry *entry);","text":"QEMU的协程接口，这里介绍了几个主要函数，没有翻译，自己看看。 The QEMU coroutine APIThe coroutine API is documented in include/block/coroutine.h. The main functions are: 12typedef void coroutine\\_fn CoroutineEntry(void \\*opaque);Coroutine *qemu\\_coroutine\\_create(CoroutineEntry *entry); When a new coroutine is started, it will begin executing the entry function. The caller can pass an opaque pointer to data needed by the coroutine. If you are familiar with multi-threaded programming, this interface is similar to pthread_create(3). The new coroutine is executed by calling qemu_coroutine_enter(): void qemu_coroutine_enter(Coroutine coroutine, void opaque);If the coroutine needs to wait for an event such as I/O completion or user input, it calls qemu_coroutine_yield(): void coroutine_fn qemu_coroutine_yield(void);The yield function transfers control back to the qemu_coroutine_enter() caller. The coroutine can be re-entered at a later point in time by calling qemu_coroutine_enter(), for example, when an I/O request has completed. ConclusionCoroutines make it possible to write sequential code that is actually executed across multiple iterations of the event loop. This is useful for code that needs to perform blocking I/O and would quickly become messy if split into a chain of callback functions. Transfer of control is always explicit using enter/yield, and there is no scheduler that automatically switches between coroutines. QEMU provides additional primitives on top of the coroutine API for wait queues, mutexes, and timers. In a future blog post I will explain how to use these primitives.","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"}]},{"title":"2016-07-29","slug":"2016-07-29","date":"2016-07-29T16:54:28.000Z","updated":"2018-12-31T11:05:54.000Z","comments":true,"path":"2016/07/30/2016-07-29/","link":"","permalink":"http://yoursite.com/2016/07/30/2016-07-29/","excerpt":"今天做了什么发现内核线程切换开销导致性能低于用协程实现的baseline。So sad….. 学习了coroutine协程的一些基本知识，下一步就是要了解qemu的协程实现了。","text":"今天做了什么发现内核线程切换开销导致性能低于用协程实现的baseline。So sad….. 学习了coroutine协程的一些基本知识，下一步就是要了解qemu的协程实现了。 有什么需要纠正的没什么要纠正的，坚持就好，可是我现在为什么在听歌。。。 有什么应该做没有做的什么都做了？好像是啊 有什么收获其实打球的时候有练到内线的技巧。 什么糟糕的事情今天的发现，意味着我要qemu再实现一遍，5555555555要哭 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]},{"title":"初窥coroutine","slug":"初窥coroutine","date":"2016-07-29T14:35:31.000Z","updated":"2018-12-31T05:38:26.000Z","comments":true,"path":"2016/07/29/初窥coroutine/","link":"","permalink":"http://yoursite.com/2016/07/29/初窥coroutine/","excerpt":"用标准C实现coroutine之间的切换很简单： 使用setjmp保存当前协程的状态 使用longjmp跳转到目标协程下面的函数coto()(short for “coroutine goto”)完成了这样的过程，首先它把参数保存到目标协程能够访问到的地方，然后它调用setjmp来保存当前协程的状态，这个函数正常返回值是0，然后它继续执行到longjmp，跳转到目标协程，在目标协程中，setjmp()返回1，这样coto()返回保存了的参数。 1234567static void *coarg;void *coto(jmp_buf here, jmp_buf there, void *arg) &#123; coarg = arg; if (setjmp(here)) return(coarg); longjmp(there, 1);&#125;","text":"用标准C实现coroutine之间的切换很简单： 使用setjmp保存当前协程的状态 使用longjmp跳转到目标协程下面的函数coto()(short for “coroutine goto”)完成了这样的过程，首先它把参数保存到目标协程能够访问到的地方，然后它调用setjmp来保存当前协程的状态，这个函数正常返回值是0，然后它继续执行到longjmp，跳转到目标协程，在目标协程中，setjmp()返回1，这样coto()返回保存了的参数。 1234567static void *coarg;void *coto(jmp_buf here, jmp_buf there, void *arg) &#123; coarg = arg; if (setjmp(here)) return(coarg); longjmp(there, 1);&#125; 另一个需要做的事情就是创建协程。这要求为协程的栈分配空间，在协程初始化栈帧，跳转到这个栈帧。通常，如果没有操作系统或者运行时系统的特殊支持，是不可能的，举个例子，看这个文章。然而如果我们可以假设这个栈在内存中是连续分布的，可变长度的数组可以在栈上分配，我们可以使用标准C99做到。（如果你的编译器不支持可变长度数组，可以使用alloca()替代） 每个协程的栈是一块用作普通进程栈的内存。为了在栈中分配一块新的内存，我们在当前的栈顶加入chunk大小的内存（这样为当前最顶部的协程进行未来可能函数调用的空间）。然后我们需要移动栈指针来指向这个新的位置，这样我们就创建了一个合适长度的可变长度数组。在计算长度的时候，我们可以利用局部变量的地址来模拟当前栈的指针。最终，一个简单的函数调用就可以创建协程的初始栈帧，并且跳转到相应的位置。 下面的函数cogo() (short for “coroutine start”)实现了这个功能，同时它在创建一个新的协程的时候还会保存当前协程的状态。12345678910111213141516#define STACKDIR - // set to + for upwards and - for downwards #define STACKSIZE (1&lt;&lt;12) static char *tos; // top of stack //创建协程 void *cogo(jmp_buf here, void (*fun)(void*), void *arg) &#123; if (tos == NULL) tos = (char*)&amp;arg; tos += STACKDIR STACKSIZE; char n[STACKDIR (tos - (char*)&amp;arg)]; coarg = n; // ensure optimizer keeps n if (setjmp(here)) return(coarg); fun(arg); abort(); &#125; Here’s a little test program to demonstrate these functions in action. 1234567891011121314151617181920212223#define MAXTHREAD 10000 static jmp_buf thread[MAXTHREAD]; static int count = 0; static void comain(void *arg) &#123; int *p = arg, i = *p; for (;;) &#123; printf(\"coroutine %d at %p arg %p\\n\", i, (void*)&amp;i, arg); int n = arc4random() % count; printf(\"jumping to %d\\n\", n); arg = coto(thread[i], thread[n], (char*)arg + 1); &#125; &#125; int main(void) &#123; while (++count &lt; MAXTHREAD) &#123; printf(\"spawning %d\\n\", count); cogo(thread[0], comain, &amp;count); &#125; return 0;&#125;","categories":[],"tags":[]},{"title":"收益值与半衰期","slug":"收益值与半衰期","date":"2016-07-29T07:41:23.000Z","updated":"2018-12-31T10:56:54.000Z","comments":true,"path":"2016/07/29/收益值与半衰期/","link":"","permalink":"http://yoursite.com/2016/07/29/收益值与半衰期/","excerpt":"看精进，看到一个有意思的概念，将生活学习中的事情分成四类： 高收益值、长半衰期事件找到真爱，学会一种有效的思维技巧，跟大牛深谈","text":"看精进，看到一个有意思的概念，将生活学习中的事情分成四类： 高收益值、长半衰期事件找到真爱，学会一种有效的思维技巧，跟大牛深谈 高收益值、短半衰期事件买流行的衣服，玩儿一下午手机游戏，扶墙自助餐 低收益值、长半衰期事件一小时书法，背三首诗，读懂哲学著作一个章节，多重复一组技能练习，认真回复一封友人的邮件 低收益值、短半衰期事件挑战或者参与一次掐架，漫无目的的刷微博，社交软件。。。 其实可以发现，哪些短半衰期的事情，都是很容易fade away的，我的生活中也充斥了与这个类似的坏习惯，比如玩儿手机，刷微博等等，希望能够通过一切强制，或者造成麻烦的方法，让我做这些事情的时候会更难一些。 人的伟大之处在于，他是一座桥梁而非目的；人的可爱之处在于，他是一个过渡，也是一个沉沦。","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"读一千本书会有什么收获","slug":"读一千本书会有什么收获","date":"2016-07-29T04:25:27.000Z","updated":"2018-12-31T10:56:31.000Z","comments":true,"path":"2016/07/29/读一千本书会有什么收获/","link":"","permalink":"http://yoursite.com/2016/07/29/读一千本书会有什么收获/","excerpt":"Quora上看到一个文章，作者读了421本书，作者认为在读了这么多书之后，他成为了一个T型的读者。对很多事情有了常识，并且在几个领域有深入。他专注了创新类，商业以及心理学，其他类型的数据被认为是奖励。","text":"Quora上看到一个文章，作者读了421本书，作者认为在读了这么多书之后，他成为了一个T型的读者。对很多事情有了常识，并且在几个领域有深入。他专注了创新类，商业以及心理学，其他类型的数据被认为是奖励。这个作者认为，读书重要是要实践，读一些，去实践一些，然后再读，这是一个比较好的循环。然而他发现，无论是哪个领域，当你阅读了超过10本书的时候，就会发现一些重复的概念。（难不成我的论文是看多了？eee…）","categories":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/categories/生活/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"2016-07-28","slug":"20160728","date":"2016-07-28T10:43:29.000Z","updated":"2018-12-31T11:06:04.000Z","comments":true,"path":"2016/07/28/20160728/","link":"","permalink":"http://yoursite.com/2016/07/28/20160728/","excerpt":"今天做了什么hexo的部署过程基本熟悉了，期间遇到了中文乱码，插入图片大小调整，标题不能解析的问题，都一一解决了，这个框架基本上还是比较适合做博客发布的。 实验方面，发现混合内存的比例不是问题，dram的容量占比少对性能的影响在5%以内。那么基本上存在两个极端，即完全使用DRAM和完全使用NVM，我将测试两种情况。 1![image][image-1]","text":"今天做了什么hexo的部署过程基本熟悉了，期间遇到了中文乱码，插入图片大小调整，标题不能解析的问题，都一一解决了，这个框架基本上还是比较适合做博客发布的。 实验方面，发现混合内存的比例不是问题，dram的容量占比少对性能的影响在5%以内。那么基本上存在两个极端，即完全使用DRAM和完全使用NVM，我将测试两种情况。 1![image][image-1] 有什么需要纠正的感觉花费了不少时间在hexo上面，这个算不算要纠正的呢？ 有什么应该做没有做的恩恩，每天都说要看kindle十分钟的 有什么收获每天抽出时间去阅读英语，背背单词，虽然没有什么实际需求，也没有考试，但是觉得对英语素养的提升还是有帮助的 什么糟糕的事情貌似没有吧，就是觉得进度慢了 周末计划时间翻阅该周记录挑选重要的部分做一个一周的summary，对一周之内有价值的东西做再一次记忆强化。每月月末做做一月小结。 好处在于对重要事情进行多次回顾，并且通过层次过滤后，留下比较简练的monthly summary记录方便回顾和查阅。","categories":[{"name":"记录","slug":"记录","permalink":"http://yoursite.com/categories/记录/"}],"tags":[{"name":"个人日志","slug":"个人日志","permalink":"http://yoursite.com/tags/个人日志/"}]}]}